{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NRS Beta 2: Newborn Risk Stratification Analytics\n",
        "## Snowflake Notebook Edition\n",
        "\n",
        "This notebook processes newborn and NICU claims data through a comprehensive 6-step pipeline:\n",
        "\n",
        "1. **Membership Processing** - Load and process member eligibility data\n",
        "2. **Newborn Identification** - Identify newborns using diagnosis and revenue codes\n",
        "3. **Claims Processing** - Load and enrich claims with reference flags\n",
        "4. **Hospital Rollup** - Aggregate hospital stays and calculate length of stay\n",
        "5. **NICU Analysis** - Identify and analyze NICU admissions with cost breakdowns\n",
        "6. **Final Export** - Combine newborn and NICU data for output\n",
        "\n",
        "**Optimized for Snowflake Notebooks**: This version features modular cells for better execution control and debugging.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udd37 Snowflake Notebook Optimizations\n",
        "\n",
        "This notebook has been restructured for optimal use in Snowflake notebook environments:\n",
        "\n",
        "**Key Changes:**\n",
        "- **Modular Cells**: The original 1400+ line code cell has been split into 10 logical sections\n",
        "- **Better Execution Control**: Each section can be executed independently for debugging\n",
        "- **Clear Documentation**: Markdown headers separate each functional area\n",
        "\n",
        "**Snowflake Notebook Integration:**\n",
        "- The notebook uses Snowpark API (Python) which runs natively in Snowflake\n",
        "- Connection management is included, but Snowflake notebooks provide a built-in session\n",
        "- All data processing happens in Snowflake's compute layer\n",
        "\n",
        "**Cell Organization:**\n",
        "1. Configuration (database, thresholds, code ranges)\n",
        "2. Imports and logging setup\n",
        "3. Connection management\n",
        "4. Date window calculation\n",
        "5. Membership processing\n",
        "6. Newborn identification\n",
        "7. Claim classification and tagging\n",
        "8. Hospital rollup\n",
        "9. NICU analysis\n",
        "10. Final export and orchestration\n",
        "\n",
        "**To Run:**\n",
        "- Execute cells sequentially from top to bottom\n",
        "- Review configuration in Section 1 before running\n",
        "- Main execution happens in the \"Execute Pipeline\" section\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration and Setup\n",
        "\n",
        "Define client settings, database parameters, clinical thresholds, and code ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION - All inputs and parameters\n",
        "# =============================================================================\n",
        "\n",
        "# Client configuration\n",
        "CLIENT_DATA = 'QUARTZ'\n",
        "CLIENT_NAME = 'QUARTZ'\n",
        "\n",
        "# Database configuration\n",
        "DATABASE = \"CSZNB_PRD_PS_PFA_DB\"\n",
        "SCHEMA = \"STAGE\"\n",
        "BASE_SCHEMA = \"BASE\"\n",
        "SUPP_SCHEMA = \"SUPP_DATA\"\n",
        "\n",
        "# Snowflake connection parameters\n",
        "SF_ACCOUNT = \"uhgdwaas.east-us-2.azure\"\n",
        "SF_ROLE = \"AZU_SDRP_CSZNB_PRD_DEVELOPER_ROLE\"\n",
        "SF_WAREHOUSE = \"CSZNB_PRD_ANALYTICS_XS_WH\"\n",
        "\n",
        "# Pipeline parameters\n",
        "AUTO_WINDOW = True   # Set to False to use manual dates below\n",
        "DRY_RUN = False      # Set to True to skip writing to Snowflake (for testing)\n",
        "DEBUG_MODE = True    # Set to True to cache intermediate dataframes for debugging\n",
        "\n",
        "# Manual date configuration (used if AUTO_WINDOW = False)\n",
        "MANUAL_BIRTH_START = \"2021-01-01\"\n",
        "MANUAL_BIRTH_END = \"2022-12-31\"\n",
        "MANUAL_RUNOUT_END = \"2023-03-31\"\n",
        "\n",
        "# Output table suffix (for testing/production)\n",
        "TABLE_SUFFIX = \"\"\n",
        "\n",
        "# =============================================================================\n",
        "# Clinical and Business Rule Thresholds\n",
        "# =============================================================================\n",
        "\n",
        "# Readmission and hospitalization thresholds\n",
        "INIT_HOSP_THRESHOLD_DAYS = 4        # Initial hospitalization window after birth\n",
        "READMIT_THRESHOLD_DAYS = 30         # Readmission window (days)\n",
        "HOSP_STAY_GAP_DAYS = 4              # Gap > 4 days between discharges = new episode\n",
        "NEWBORN_SERVICE_WINDOW_DAYS = 4     # Services within 4 days of birth count as newborn\n",
        "\n",
        "# Cost thresholds\n",
        "HIGH_COST_CLAIM_THRESHOLD = 500000           # CMS extreme outlier definition ($500k)\n",
        "NICU_LOW_COST_PER_DAY_THRESHOLD = 150       # Data quality: minimum expected NICU cost/day\n",
        "\n",
        "# Length of stay thresholds\n",
        "INAPPROPRIATE_NICU_MAX_LOS = 5      # Max LOS for inappropriate NICU (DRG-based, short stay)\n",
        "LONG_STAY_THRESHOLD = 3             # LOS >= 3 days = \"Long Stay\"\n",
        "\n",
        "# DRG code ranges for NICU identification\n",
        "NICU_MS_DRG_RANGE = (580, 640)      # MS-DRG 580-640: Neonate diagnoses\n",
        "NICU_APR_DRG_RANGE = (789, 795)     # APR-DRG 789-795: Extreme neonate conditions\n",
        "\n",
        "# Revenue code ranges  \n",
        "NICU_REV_CODE_RANGE = (170, 179)    # Rev codes 170-179: Nursery levels (I-IV)\n",
        "ROOM_BOARD_REV_PREFIXES = [\"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"020\"]\n",
        "\n",
        "# Manageable and critical care CPT codes\n",
        "MANAGEABLE_CPT_CODES = [\"99233\", \"99479\", \"99480\", \"99478\", \"99231\", \"99232\", \"99462\"]\n",
        "CRITICAL_CARE_CPT_CODES = [\"99468\", \"99469\", \"99471\", \"99472\"]\n",
        "\n",
        "# Place of Service codes\n",
        "POS_INPATIENT = \"21\"\n",
        "POS_EMERGENCY = \"23\"\n",
        "\n",
        "# Discharge status code groups (for prioritization)\n",
        "DISCHARGE_STATUS_DEATH = \"20\"\n",
        "DISCHARGE_STATUS_AMA = \"07\"\n",
        "DISCHARGE_STATUS_TRANSFERS = [\"02\", \"05\", \"66\", \"43\", \"62\", \"63\", \"65\"]\n",
        "DISCHARGE_STATUS_SNF = \"30\"\n",
        "DISCHARGE_STATUS_HOME = [\"01\", \"06\"]\n",
        "DISCHARGE_STATUS_EXCLUDED = [\"04\", \"41\", \"50\", \"51\", \"70\", \"03\", \"64\"]\n",
        "\n",
        "# =============================================================================\n",
        "# Configuration Validation\n",
        "# =============================================================================\n",
        "if not CLIENT_DATA:\n",
        "    raise ValueError(\"CLIENT_DATA must be set\")\n",
        "if TABLE_SUFFIX and not TABLE_SUFFIX.startswith('_'):\n",
        "    raise ValueError(\"TABLE_SUFFIX must start with underscore or be empty\")\n",
        "if INIT_HOSP_THRESHOLD_DAYS < 1:\n",
        "    raise ValueError(\"INIT_HOSP_THRESHOLD_DAYS must be >= 1\")\n",
        "if READMIT_THRESHOLD_DAYS < 1:\n",
        "    raise ValueError(\"READMIT_THRESHOLD_DAYS must be >= 1\")\n",
        "\n",
        "print(f\"\u2713 Configuration validated for client: {CLIENT_DATA}\")\n",
        "print(f\"\u2713 Database: {DATABASE}\")\n",
        "print(f\"\u2713 Table suffix: {TABLE_SUFFIX}\")\n",
        "print(f\"\u2713 Dry-run mode: {DRY_RUN}\")\n",
        "print(f\"\u2713 Debug mode: {DEBUG_MODE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pipeline Implementation\n",
        "\n",
        "The following cells contain the pipeline functions organized into logical groups.\n",
        "\n",
        "**Note for Snowflake Notebooks**: If running in a Snowflake notebook environment, you can use the built-in `snowflake.snowpark.session` instead of creating a new connection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.functions import (\n",
        "    col, row_number, to_date, concat, lit, when,\n",
        "    min as smin, max as smax, greatest, least,\n",
        "    datediff, first_value, sum as ssum, abs as sabs,\n",
        "    coalesce, length, lag, sql_expr, to_char,\n",
        "    substring, count_distinct, try_cast\n",
        ")\n",
        "from snowflake.snowpark.window import Window\n",
        "from cryptography.hazmat.primitives import serialization\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "import pandas as pd\n",
        "import os\n",
        "import logging\n",
        "import builtins\n",
        "import numpy as np\n",
        "from datetime import timedelta, datetime, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Logging setup\n",
        "# ---------------------------------------------\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
        "    handlers=[logging.StreamHandler()])\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Configuration\n",
        "# ---------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connection Management Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_snowflake_session():\n",
        "    pkey_pem = os.getenv(\"MY_SF_PKEY\")\n",
        "    pkey = serialization.load_pem_private_key(\n",
        "        pkey_pem.encode(\"utf-8\"),\n",
        "        password=None,\n",
        "        backend=default_backend()\n",
        "    )\n",
        "    connection = {\n",
        "        \"account\": \"uhgdwaas.east-us-2.azure\",\n",
        "        \"user\": os.getenv('MY_SF_USER'),\n",
        "        \"private_key\": pkey,\n",
        "        \"role\": \"AZU_SDRP_CSZNB_PRD_DEVELOPER_ROLE\",\n",
        "        \"warehouse\": \"CSZNB_PRD_ANALYTICS_XS_WH\",\n",
        "        \"database\": \"CSZNB_PRD_PS_PFA_DB\",\n",
        "        \"schema\": \"STAGE\"\n",
        "    }\n",
        "    return Session.builder.configs(connection).create()\n",
        "\n",
        "def get_table_name(table_type: str, client: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Build fully qualified table names consistently.\n",
        "    \n",
        "    Args:\n",
        "        table_type: Type of table ('medical', 'membership', 'ps_membership', 'ps_newborns', 'ref_*')\n",
        "        client: Client name (uses CLIENT_DATA from config if None)\n",
        "    \n",
        "    Returns:\n",
        "        str: Fully qualified table name\n",
        "    \"\"\"\n",
        "    client = client or CLIENT_DATA\n",
        "    \n",
        "    if table_type == 'medical':\n",
        "        return f\"{DATABASE}.{SCHEMA}.FA_MEDICAL_{client}\"\n",
        "    elif table_type == 'membership':\n",
        "        return f\"{DATABASE}.{SCHEMA}.FA_MEMBERSHIP_{client}\"\n",
        "    elif table_type == 'ps_membership':\n",
        "        return f\"{DATABASE}.{BASE_SCHEMA}.PS_MEMBERSHIP_{client}{TABLE_SUFFIX}\"\n",
        "    elif table_type == 'ps_newborns':\n",
        "        return f\"{DATABASE}.{BASE_SCHEMA}.PS_NEWBORNS_{client}{TABLE_SUFFIX}\"\n",
        "    elif table_type.startswith('ref_'):\n",
        "        ref_name = table_type[4:].upper()\n",
        "        return f\"{DATABASE}.{SUPP_SCHEMA}.{ref_name}\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown table type: {table_type}\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Auto-calculate birth window dates\n",
        "# ---------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Date Window Calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_birth_window(session, client_data):\n",
        "    logger.info(\"Calculating birth and runout window from source data\")\n",
        "    table = f\"CSZNB_PRD_PS_PFA_DB.STAGE.FA_MEDICAL_{client_data}\"\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "    MIN(SRVC_FROM_DT) AS MIN_FROMDATE,\n",
        "    MAX(SRVC_FROM_DT) AS MAX_FROMDATE,\n",
        "    MAX(PROCESS_DT) AS MAX_PAIDDATE\n",
        "    FROM {table}\n",
        "    WHERE SRVC_FROM_DT IS NOT NULL AND PROCESS_DT IS NOT NULL\n",
        "    \"\"\"\n",
        "    df = session.sql(query).to_pandas()\n",
        "    min_dt = pd.to_datetime(df.at[0, 'MIN_FROMDATE'])\n",
        "    max_dt = pd.to_datetime(df.at[0, 'MAX_FROMDATE'])\n",
        "    max_ro_dt = pd.to_datetime(df.at[0, 'MAX_PAIDDATE'])\n",
        "    \n",
        "    if pd.isna(min_dt) or pd.isna(max_dt):\n",
        "        raise ValueError(\"FROMDATE range is invalid. Cannot determine birth window.\")\n",
        "    \n",
        "    num_months = (max_dt.year - min_dt.year) * 12 + (max_dt.month - min_dt.month) + 1\n",
        "    if num_months < 24:\n",
        "        raise ValueError(f\"Only {num_months} months available. Minimum 24 months required.\")\n",
        "    \n",
        "    last_complete_month_end = max_dt.replace(day=1) - pd.Timedelta(days=1)\n",
        "    runout_end = last_complete_month_end\n",
        "    runout_start = runout_end - relativedelta(months=3) + pd.Timedelta(days=1)\n",
        "    birth_window_end = runout_start - pd.Timedelta(days=1)\n",
        "    birth_window_start = birth_window_end - relativedelta(months=24) + pd.Timedelta(days=1)\n",
        "    birth_window_mid = birth_window_start + relativedelta(months=12)\n",
        "    \n",
        "    birth_window_start = pd.to_datetime(birth_window_start).to_pydatetime()\n",
        "    birth_window_end = pd.to_datetime(birth_window_end).to_pydatetime()\n",
        "    runout_end = pd.to_datetime(runout_end).to_pydatetime()\n",
        "    \n",
        "    logger.info(f\"Birth window: {birth_window_start.date()} to {birth_window_end.date()}\")\n",
        "    logger.info(f\"Runout end: {runout_end.date()}\")\n",
        "    return birth_window_start, birth_window_end, birth_window_mid, runout_end\n",
        "\n",
        "def _pydate(x):\n",
        "    \"\"\"\n",
        "    Convert various date types to Python date object.\n",
        "    \n",
        "    Args:\n",
        "        x: Date-like object (pandas Timestamp, datetime, or date)\n",
        "        \n",
        "    Returns:\n",
        "        date: Python date object\n",
        "        \n",
        "    Raises:\n",
        "        TypeError: If x is not a recognized date type\n",
        "    \"\"\"\n",
        "    if hasattr(x, \"to_pydatetime\"):\n",
        "        return x.to_pydatetime().date()\n",
        "    if isinstance(x, datetime):\n",
        "        return x.date()\n",
        "    if isinstance(x, date):\n",
        "        return x\n",
        "    raise TypeError(type(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Membership Processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_membership(session: Session, client: str, birth_start, birth_mid, birth_end, client_nm: str):\n",
        "    \"\"\"\n",
        "    Process membership data and create PS_MEMBERSHIP table.\n",
        "\n",
        "    Uses MEM_EFF_DT and MEM_EXP_DT directly from source.\n",
        "    Processes ALL enrollment periods per member (not just most recent).\n",
        "    Aggregates member-months per member per study period.\n",
        "\n",
        "    Args:\n",
        "        session: Snowpark session\n",
        "        client: Client identifier\n",
        "        birth_start: Start of birth window\n",
        "        birth_mid: Midpoint of birth window (splits Previous/Current periods)\n",
        "        birth_end: End of birth window\n",
        "        client_nm: Client name for output\n",
        "    \"\"\"\n",
        "\n",
        "    birth_start = _pydate(birth_start)\n",
        "    birth_mid = _pydate(birth_mid)\n",
        "    birth_end = _pydate(birth_end)\n",
        "\n",
        "\n",
        "    src = (session.table(f\"FA_MEMBERSHIP_{client}\")\n",
        "           .filter(col(\"INDV_ID\").is_not_null() & col(\"YEARMO\").is_not_null())\n",
        "           # YEARMO like '202401' -> 2024-01-01\n",
        "           .with_column(\"MM_DATE\", to_date(concat(col(\"YEARMO\"), lit(\"01\")), \"YYYYMMDD\")))\n",
        "\n",
        "    # Step 1: Get most recent demographics per member (by MM_DATE desc)\n",
        "    w = Window.partition_by(\"INDV_ID\").order_by(col(\"MM_DATE\").desc())\n",
        "    demographics = (src.with_column(\"RN\", row_number().over(w))\n",
        "                       .filter(col(\"RN\") == 1)\n",
        "                       .select(\"INDV_ID\", \"GENDER\", \"BTH_DT\", \"BUS_LINE_CD\", \"PRDCT_CD\", \"STATE\"))\n",
        "\n",
        "    # Step 2: Get ALL distinct enrollment periods per member (no row_number filter)\n",
        "    enrollment = (src.select(\"INDV_ID\",\n",
        "                            col(\"MEM_EFF_DT\").cast(\"DATE\").alias(\"MEM_EFF_DT\"),\n",
        "                            col(\"MEM_EXP_DT\").cast(\"DATE\").alias(\"MEM_EXP_DT\"))\n",
        "                     .distinct())\n",
        "\n",
        "    # Step 3: Join demographics to all enrollment periods\n",
        "    base = enrollment.join(demographics, \"INDV_ID\")\n",
        "\n",
        "    prev_high = birth_mid - timedelta(days=1)  # first window ends day before mid\n",
        "    prev_high = _pydate(prev_high)\n",
        "\n",
        "    # Calculate overlaps using MEM_EFF_DT and MEM_EXP_DT directly (no aliasing)\n",
        "    eff_prev = greatest(col(\"MEM_EFF_DT\"), lit(birth_start))\n",
        "    exp_prev = least(col(\"MEM_EXP_DT\"), lit(prev_high))\n",
        "    eff_curr = greatest(col(\"MEM_EFF_DT\"), lit(birth_mid))\n",
        "    exp_curr = least(col(\"MEM_EXP_DT\"), lit(birth_end))\n",
        "\n",
        "    with_mmyr = (base\n",
        "        .with_column(\"MMYR1\", when(exp_prev < eff_prev, lit(0))\n",
        "            .otherwise(datediff(\"month\", eff_prev, exp_prev) + lit(1)))\n",
        "        .with_column(\"MMYR2\", when(exp_curr < eff_curr, lit(0))\n",
        "            .otherwise(datediff(\"month\", eff_curr, exp_curr) + lit(1)))\n",
        "        .with_column(\"AGE\",\n",
        "            when(col(\"BTH_DT\").is_null(), lit(None))\n",
        "            .otherwise(datediff(\"year\", col(\"BTH_DT\"), lit(birth_end))))\n",
        "        .with_column(\"CLIENT_NAME\", lit(client_nm))\n",
        "        .with_column(\"PREVIOUS_PERIOD\",\n",
        "            lit(f\"{birth_start:%b %Y} - {prev_high:%b %Y}\"))\n",
        "        .with_column(\"CURRENT_PERIOD\",\n",
        "            lit(f\"{birth_mid:%b %Y} - {birth_end:%b %Y}\"))\n",
        "    )\n",
        "\n",
        "    # Materialize two study-year slices and prepare for aggregation\n",
        "    prev_df = (with_mmyr.filter(col(\"MMYR1\") > 0)\n",
        "               .with_column(\"STUDY_YR\", lit(\"Previous\"))\n",
        "               .with_column(\"MEMBER_MONTHS\", col(\"MMYR1\")))\n",
        "\n",
        "    curr_df = (with_mmyr.filter(col(\"MMYR2\") > 0)\n",
        "               .with_column(\"STUDY_YR\", lit(\"Current\"))\n",
        "               .with_column(\"MEMBER_MONTHS\", col(\"MMYR2\")))\n",
        "\n",
        "    # Union and aggregate member-months per member per study year\n",
        "    member_df = (prev_df.union_all(curr_df)\n",
        "                 .group_by(\"INDV_ID\", \"STUDY_YR\", \"GENDER\", \"BTH_DT\", \"BUS_LINE_CD\",\n",
        "                           \"PRDCT_CD\", \"STATE\", \"AGE\", \"CLIENT_NAME\",\n",
        "                           \"PREVIOUS_PERIOD\", \"CURRENT_PERIOD\")\n",
        "                 .agg(ssum(\"MEMBER_MONTHS\").alias(\"MEMBER_MONTHS\")))\n",
        "\n",
        "    # Write PS_MEMBERSHIP_<CLIENT>\n",
        "    export_to_snowflake(member_df, f\"CSZNB_PRD_PS_PFA_DB.BASE.PS_MEMBERSHIP_{client}_TST\")\n",
        "# ---------------------------------------------\n",
        "# Export final DataFrame to Snowflake\n",
        "# ---------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Newborn Identification Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_newborn_keys(session, client_data, birth_start, birth_end, runout_end):\n",
        "    \"\"\"\n",
        "    Identify all distinct INDV_IDs with birth-related claims during the birth window.\n",
        "    Uses reference tables in SUPP_DATA instead of in-memory dictionaries.\n",
        "    \"\"\"\n",
        "    table_name = f\"FA_MEDICAL_{client_data}\"\n",
        "    df = session.table(table_name).filter(\n",
        "        (col(\"SRVC_FROM_DT\") >= birth_start) &\n",
        "        (col(\"SRVC_FROM_DT\") <= birth_end) &\n",
        "        (col(\"PROCESS_DT\") <= runout_end) &\n",
        "        col(\"INDV_ID\").is_not_null()\n",
        "    )\n",
        "    # --- Load reference tables ---\n",
        "    rev_ref = session.table(\"SUPP_DATA.REF_NEWBORN_REVCODE\").select(col(\"CODE\").alias(\"REV_CODE\"))\n",
        "    icd_ref = session.table(\"SUPP_DATA.REF_NEWBORN_ICD\").select(col(\"CODE\").alias(\"ICD_CODE\"))\n",
        "    msdrg_ref = session.table(\"SUPP_DATA.REF_NICU_MSDRG\").select(col(\"CODE\").alias(\"MSDRG\"))\n",
        "    aprdrg_ref = session.table(\"SUPP_DATA.REF_NICU_APRDRG\").select(col(\"CODE\").alias(\"APRDRG\"))\n",
        "    # --- Join claims to reference tables ---\n",
        "    cond_rev = df[\"RVNU_CD\"].cast(\"string\") == rev_ref[\"REV_CODE\"]\n",
        "    cond_icd = (\n",
        "        (df[\"DIAG_1_CD\"].cast(\"string\") == icd_ref[\"ICD_CODE\"]) |\n",
        "        (df[\"DIAG_2_CD\"].cast(\"string\") == icd_ref[\"ICD_CODE\"]) |\n",
        "        (df[\"DIAG_3_CD\"].cast(\"string\") == icd_ref[\"ICD_CODE\"]) |\n",
        "        (df[\"DIAG_4_CD\"].cast(\"string\") == icd_ref[\"ICD_CODE\"]) |\n",
        "        (df[\"DIAG_5_CD\"].cast(\"string\") == icd_ref[\"ICD_CODE\"])\n",
        "    )\n",
        "    cond_msdrg = df[\"DERIV_DRG_CD\"].substr(1,3) == msdrg_ref[\"MSDRG\"]\n",
        "    cond_aprdrg = df[\"DERIV_DRG_CD\"].substr(1,3) == aprdrg_ref[\"APRDRG\"]\n",
        "    newborn_keys = (\n",
        "        df.join(rev_ref, cond_rev, \"left\")\n",
        "          .join(icd_ref, cond_icd, \"left\")\n",
        "          .join(msdrg_ref, cond_msdrg, \"left\")\n",
        "          .join(aprdrg_ref, cond_aprdrg, \"left\")\n",
        "          .filter(\n",
        "              col(\"REV_CODE\").is_not_null() |\n",
        "              col(\"ICD_CODE\").is_not_null() |\n",
        "              col(\"MSDRG\").is_not_null() |\n",
        "              col(\"APRDRG\").is_not_null()\n",
        "          )\n",
        "          .select(\"INDV_ID\").distinct()\n",
        "          .to_pandas()\n",
        "    )\n",
        "    return newborn_keys[\"INDV_ID\"].tolist()\n",
        "\n",
        "\n",
        "def load_newborn_claims(session, client_data, newborn_keys, birth_start, birth_end, runout_end):\n",
        "    \"\"\"\n",
        "    Load newborn claims from FA_MEDICAL table for identified newborn keys.\n",
        "\n",
        "    Returns claims with original column names except:\n",
        "    - SBMT_CHRG_AMT -> BILLED\n",
        "    - DRG.substr(0,3) -> DRG\n",
        "    \"\"\"\n",
        "    fa_medical = session.table(f\"FA_MEDICAL_{client_data}\")\n",
        "\n",
        "    if not newborn_keys:\n",
        "        logger.warning(\"No newborn keys found - skipping claims pull\")\n",
        "        return session.create_dataframe([], schema=[\"INDV_ID\"])\n",
        "\n",
        "    newborn_keys = [str(k) for k in newborn_keys if k is not None]\n",
        "\n",
        "    claims_df = (\n",
        "        fa_medical\n",
        "        .filter((fa_medical['SRVC_FROM_DT'] >= birth_start) & (fa_medical['SRVC_FROM_DT'] <= birth_end))\n",
        "        .filter((fa_medical['PROCESS_DT'] <= runout_end))\n",
        "        .filter(fa_medical['INDV_ID'].isin(newborn_keys))\n",
        "        .select(\n",
        "            fa_medical['INDV_ID'],\n",
        "            fa_medical['CLM_AUD_NBR'],\n",
        "            fa_medical['SRVC_FROM_DT'],\n",
        "            fa_medical['LST_SRVC_DT'].alias('SRVC_THRU_DT'),\n",
        "            fa_medical['PROCESS_DT'],\n",
        "            fa_medical['ADMIT_DT'],\n",
        "            fa_medical['DISCH_DT'],\n",
        "            fa_medical['DIAG_1_CD'],\n",
        "            fa_medical['DIAG_2_CD'],\n",
        "            fa_medical['DIAG_3_CD'],\n",
        "            fa_medical['DIAG_4_CD'],\n",
        "            fa_medical['DIAG_5_CD'],\n",
        "            fa_medical['PROC_1_CD'],\n",
        "            fa_medical['PROC_2_CD'],\n",
        "            fa_medical['PROC_3_CD'],\n",
        "            fa_medical['PROC_CD'],\n",
        "            fa_medical['DSCHRG_STS'],\n",
        "            fa_medical['SBMT_CHRG_AMT'].alias('BILLED'),\n",
        "            fa_medical['DERIV_DRG_CD'].substr(0, 3).alias('DRG'),\n",
        "            fa_medical['NET_PD_AMT'],\n",
        "            fa_medical['PL_OF_SRVC_CD'],\n",
        "            fa_medical['RVNU_CD'],\n",
        "            fa_medical['PROV_TIN'],\n",
        "            fa_medical['PROV_FULL_NM'],\n",
        "            fa_medical['PROV_STATE'],\n",
        "            fa_medical['PROV_TYP_CD']\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return claims_df\n",
        "\n",
        "\n",
        "def create_fa_elig(session: Session, client: str):\n",
        "    \"\"\"\n",
        "    Returns a Snowpark DataFrame containing the most recent row per INDV_ID\n",
        "    from PS_MEMBERSHIP_<client>, preferring 'Current' over 'Previous'.\n",
        "    \"\"\"\n",
        "    src = session.table(f\"CSZNB_PRD_PS_PFA_DB.BASE.PS_MEMBERSHIP_{client}_TST\")\n",
        "    # Prefer 'Current' study year; if MEM_EXP exists, use it as a tie-breaker\n",
        "    prefer = when(col(\"STUDY_YR\") == lit(\"Current\"), lit(0)).otherwise(lit(1))\n",
        "    order_cols = [prefer]\n",
        "    if \"MEM_EXP\" in src.columns:\n",
        "        order_cols.append(col(\"MEM_EXP\").desc_nulls_last())\n",
        "    w = Window.partition_by(\"INDV_ID\").order_by(*order_cols)\n",
        "    elig_df = (        src.with_column(\"RN\", row_number().over(w))           .filter(col(\"RN\") == 1)           .select(               col(\"INDV_ID\"),               col(\"GENDER\"),               col(\"BTH_DT\"),               col(\"BUS_LINE_CD\"),               col(\"PRDCT_CD\"),               col(\"STATE\")           )    )\n",
        "    return elig_df\n",
        "\n",
        "\n",
        "def merge_eligibility(session, client_data, newborn_keys, claims_df, elig_df):\n",
        "    \"\"\"\n",
        "    Join eligibility details for each newborn using the ELIG table.\n",
        "    Assumes eligibility is at the MEMBER_ID level and static for now.\n",
        "    \"\"\"\n",
        "    merged = claims_df.join(elig_df, claims_df[\"INDV_ID\"] == elig_df[\"INDV_ID\"], \"left\")\n",
        "    elig_non_key_vals = [c for c in elig_df.columns if c.upper() != \"INDV_ID\"]       # Explicitly state the columns we want to keep and drop the duplicate INDV_ID column created on the join\n",
        "    result = merged.select(        claims_df[\"INDV_ID\"].alias(\"INDV_ID\"),        *[col(f'\"{c}\"') for c in claims_df.columns if c.upper() != \"INDV_ID\"],        *[col(f'\"{c}\"') for c in elig_non_key_vals]    )     #result = result.with_column_renamed(\"l_0030_INDV_ID\", \"INDV_ID\")\n",
        "    return result\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Claim Classification and Reference Tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assign_claim_type(df):\n",
        "    # Define conditions for CLAIM_TYPE assignment\n",
        "    return (\n",
        "        df.with_column(\n",
        "            \"CLAIM_TYPE\",\n",
        "            when(\n",
        "                (col(\"PL_OF_SRVC_CD\") == POS_INPATIENT) |\n",
        "                (col(\"RVNU_CD\").between(\"0100\", \"0210\")) |\n",
        "                (col(\"RVNU_CD\") == \"0987\") |\n",
        "                (col(\"PROC_CD\").between(\"99221\", \"99239\")) |\n",
        "                (col(\"PROC_CD\").between(\"99251\", \"99255\")) |\n",
        "                (col(\"PROC_CD\").between(\"99261\", \"99263\")) |\n",
        "                (col(\"DRG\").is_not_null()),\n",
        "                lit(\"IP\")\n",
        "            ).when(\n",
        "                (col(\"PL_OF_SRVC_CD\") == POS_EMERGENCY) |\n",
        "                (col(\"PROC_CD\").isin([\"99281\", \"99282\", \"99283\", \"99284\", \"99285\", \"99286\", \"99287\", \"99288\"])) |\n",
        "                (col(\"RVNU_CD\").startswith(\"045\")) |\n",
        "                (col(\"RVNU_CD\") == \"0981\"),\n",
        "                lit(\"ER\")\n",
        "            ).otherwise(lit(\"OP\"))\n",
        "        )\n",
        "    )\n",
        "\n",
        "def tag_icd_flag(session, claims_df, ref_table_name, diag_cols, flag_name):\n",
        "    \"\"\"\n",
        "    Tag claims with ICD diagnosis codes from reference table.\n",
        "    \n",
        "    Performance optimizations:\n",
        "    - Filters null diagnosis codes before union (reduces row count ~60-80%)\n",
        "    - Uses distinct to deduplicate diagnosis matches\n",
        "    \"\"\"\n",
        "    ref_icd = session.table(ref_table_name).select(col(\"CODE\").cast(\"STRING\").alias(\"ICD_CODE\")).distinct()\n",
        "    diag_union = None\n",
        "    \n",
        "    for diag_col in diag_cols:\n",
        "        diag_part = claims_df.select(\n",
        "            col(\"INDV_ID\"),\n",
        "            col(\"CLM_AUD_NBR\"),\n",
        "            col(diag_col).cast(\"STRING\").alias(\"DIAG_CODE\")\n",
        "        ).filter(col(diag_col).is_not_null())  # Filter nulls to reduce union size\n",
        "        \n",
        "        diag_union = diag_part if diag_union is None else diag_union.union_all(diag_part)\n",
        "    \n",
        "    # Deduplicate before join - significantly improves performance\n",
        "    diag_union = diag_union.distinct()\n",
        "    \n",
        "    diag_flagged = diag_union.join(ref_icd, diag_union[\"DIAG_CODE\"] == ref_icd[\"ICD_CODE\"]) \\\n",
        "                             .select(\n",
        "                                 col(\"INDV_ID\").alias(\"MATCH_INDV_ID\"),\n",
        "                                 col(\"CLM_AUD_NBR\").alias(\"MATCH_CLAIMNO\")\n",
        "                             ).distinct()\n",
        "    \n",
        "    flagged_claims_df = claims_df.join(\n",
        "        diag_flagged,\n",
        "        on=(claims_df[\"INDV_ID\"] == diag_flagged[\"MATCH_INDV_ID\"]) & (claims_df[\"CLM_AUD_NBR\"] == diag_flagged[\"MATCH_CLAIMNO\"]),\n",
        "        how=\"left\"\n",
        "    ).with_column(\n",
        "        flag_name,\n",
        "        col(\"MATCH_CLAIMNO\").is_not_null()\n",
        "    ).drop(\"MATCH_INDV_ID\", \"MATCH_CLAIMNO\")\n",
        "    \n",
        "    return flagged_claims_df\n",
        "\n",
        "\n",
        "def tag_rev_flag(session, claims_df, ref_table_name, flag_name):\n",
        "    ref_rev = session.table(ref_table_name).select(col(\"CODE\").cast(\"STRING\").alias(\"REV_CODE\")).distinct()\n",
        "    flagged = claims_df.join(        ref_rev,        claims_df[\"RVNU_CD\"].cast(\"STRING\") == ref_rev[\"REV_CODE\"],        how=\"left\"    ).with_column(        flag_name,        col(\"REV_CODE\").is_not_null()    ).drop(\"REV_CODE\")\n",
        "    return flagged\n",
        "\n",
        "\n",
        "def tag_drg_flag(session, claims_df, ref_table_name, flag_name):\n",
        "    ref_drg = session.table(ref_table_name).select(col(\"CODE\").cast(\"STRING\").alias(\"DRG_CODE\")).distinct()\n",
        "    flagged = claims_df.with_column(\"DRG_3\", col(\"DRG\").cast(\"STRING\").substr(1, 3)) \\\n",
        "        .join(            ref_drg,            col(\"DRG_3\") == ref_drg[\"DRG_CODE\"],            how=\"left\"        ).with_column(            flag_name,            col(\"DRG_CODE\").is_not_null()        ).drop(\"DRG_CODE\", \"DRG_3\")\n",
        "    return flagged\n",
        "\n",
        "\n",
        "def tag_all_reference_flags(session, claims_df):\n",
        "    \"\"\"\n",
        "    Tag claims with newborn/NICU reference flags from lookup tables.\n",
        "    \n",
        "    Args:\n",
        "        session: Snowpark session\n",
        "        claims_df: Claims DataFrame to tag\n",
        "        \n",
        "    Returns:\n",
        "        Tagged claims DataFrame\n",
        "        \n",
        "    Note:\n",
        "        Uses lazy evaluation - does NOT cache intermediate results.\n",
        "        Final caching happens in main() after column selection for optimal performance.\n",
        "    \"\"\"\n",
        "    diag_cols = ['DIAG_1_CD', 'DIAG_2_CD', 'DIAG_3_CD', 'DIAG_4_CD', 'DIAG_5_CD']\n",
        "    \n",
        "    # ICD tags - NO intermediate caching\n",
        "    logger.info(\"Tagging ICD codes (4 tags)...\")\n",
        "    icd_tags = [\n",
        "        ('SUPP_DATA.REF_NEWBORN_ICD', 'NEWBORN_ICD'),\n",
        "        ('SUPP_DATA.REF_SINGLETON_ICD', 'SINGLE'),\n",
        "        ('SUPP_DATA.REF_TWIN_ICD', 'TWIN'),\n",
        "        ('SUPP_DATA.REF_MULTIPLE_ICD', 'MULTIPLE')\n",
        "    ]\n",
        "    for i, (ref_table, flag) in enumerate(icd_tags, 1):\n",
        "        logger.info(f\"  [{i}/4] Tagging {flag}...\")\n",
        "        claims_df = tag_icd_flag(session, claims_df, ref_table, diag_cols, flag)\n",
        "    \n",
        "    # Revenue code tags - NO intermediate caching\n",
        "    logger.info(\"Tagging revenue codes (2 tags)...\")\n",
        "    rev_tags = [\n",
        "        ('SUPP_DATA.REF_NEWBORN_REVCODE', 'NEWBORN_REV'),\n",
        "        ('SUPP_DATA.REF_NICU_REVCODE', 'NICU_REV')\n",
        "    ]\n",
        "    for i, (ref_table, flag) in enumerate(rev_tags, 1):\n",
        "        logger.info(f\"  [{i}/2] Tagging {flag}...\")\n",
        "        claims_df = tag_rev_flag(session, claims_df, ref_table, flag)\n",
        "    \n",
        "    # DRG tags - NO intermediate caching\n",
        "    logger.info(\"Tagging DRG codes (2 tags)...\")\n",
        "    drg_tags = [\n",
        "        ('SUPP_DATA.REF_NICU_MSDRG', 'NICU_MSDRG'),\n",
        "        ('SUPP_DATA.REF_NICU_APRDRG', 'NICU_APRDRG')\n",
        "    ]\n",
        "    for i, (ref_table, flag) in enumerate(drg_tags, 1):\n",
        "        logger.info(f\"  [{i}/2] Tagging {flag}...\")\n",
        "        claims_df = tag_drg_flag(session, claims_df, ref_table, flag)\n",
        "    \n",
        "    logger.info(\"\u2713 All reference flags tagged (using lazy evaluation)\")\n",
        "    return claims_df\n",
        "\n",
        "\n",
        "def newborn_rollup(session, client, claims_df):\n",
        "    \"\"\"\n",
        "    Snowpark version of apply_birth_type_hierarchy_and_aggregate.\n",
        "\n",
        "    Input: claims_df Snowpark DF with flags: NEWBORN_ICD, NEWBORN_REV, MULTIPLE, TWIN, SINGLE,\n",
        "           plus INDV_ID, BTH_DT, SRVC_FROM_DT, NICU_REV, NICU_MSDRG, NICU_APRDRG, NET_PD_AMT, etc.\n",
        "    Output: Snowpark DF of newborn_claims (enriched and filtered) like your Pandas version.\n",
        "    \"\"\"     \n",
        "    # 0) Ensure date types are DATE (if needed)\n",
        "    c = (claims_df     \n",
        "         .with_column(\"BTH_DT\", col(\"BTH_DT\").cast(\"DATE\"))         \n",
        "         .with_column(\"SRVC_FROM_DT\", col(\"SRVC_FROM_DT\").cast(\"DATE\")))\n",
        "    \n",
        "    # 1) Per-claim birth type priority (Multiple > Twin > Single)\n",
        "    c = (c         \n",
        "         .with_column(\"BIRTH_PRI\",            \n",
        "                      when(col(\"MULTIPLE\"), lit(3))            \n",
        "                      .when(col(\"TWIN\"),  lit(2))            \n",
        "                      .when(col(\"SINGLE\"),  lit(1))            \n",
        "                      .otherwise(lit(0)))         \n",
        "         .with_column(\"BIRTH_TYPE\",            \n",
        "                      when(col(\"BIRTH_PRI\")==3, lit(\"Multiple\"))            \n",
        "                      .when(col(\"BIRTH_PRI\")==2, lit(\"Twin\"))            \n",
        "                      .when(col(\"BIRTH_PRI\")==1, lit(\"Single\"))            \n",
        "                      .otherwise(lit(\"Unknown\")))    )\n",
        "    \n",
        "    # 2) Likely newborn records (same as Pandas filter)\n",
        "    newborn_only = c.filter(col(\"NEWBORN_ICD\") | col(\"NEWBORN_REV\"))\n",
        "    \n",
        "    # 3) Group per baby: INDV_ID + BTH_DT\n",
        "    #    - pick the highest priority BIRTH_TYPE (via max priority, then map)\n",
        "    #    - SVC_DATE = min(FROMDATE)\n",
        "    #    - NICU flags = any -> max over boolean cast to int\n",
        "    newborns = (newborn_only\n",
        "        .group_by(\"INDV_ID\", \"BTH_DT\")        \n",
        "        .agg(\n",
        "            smax(\"BIRTH_PRI\").alias(\"MAX_PRI\"),            \n",
        "            smin(\"SRVC_FROM_DT\").alias(\"SVC_DATE\"),            \n",
        "            smax(when(col(\"NICU_REV\"),   \n",
        "                      lit(1)).otherwise(lit(0))).alias(\"HAS_NICU_REV\"),            \n",
        "            smax(when(col(\"NICU_MSDRG\"), lit(1)).otherwise(lit(0))).alias(\"HAS_NICU_MSDRG\"),       \n",
        "            smax(when(col(\"NICU_APRDRG\"),lit(1)).otherwise(lit(0))).alias(\"HAS_NICU_APRDRG\"),        \n",
        "        )          \n",
        "        .with_column(\"BIRTH_TYPE\",       \n",
        "            when(col(\"MAX_PRI\")==3, lit(\"Multiple\"))            \n",
        "            .when(col(\"MAX_PRI\")==2, lit(\"Twin\"))\n",
        "            .when(col(\"MAX_PRI\")==1, lit(\"Single\"))\n",
        "            .otherwise(lit(\"Unknown\")))\n",
        "        .drop(\"MAX_PRI\")    \n",
        "    )\n",
        "    \n",
        "    # 4) Derived baby-level fields\n",
        "    newborns = (newborns        .with_column(\"IN_DAYS\",            (sabs(datediff(\"day\", col(\"SVC_DATE\"), col(\"BTH_DT\"))) <= lit(NEWBORN_SERVICE_WINDOW_DAYS)))        .with_column(\"BABY_TYPE\",            when( (col(\"HAS_NICU_REV\")==1) | (col(\"HAS_NICU_MSDRG\")==1) | (col(\"HAS_NICU_APRDRG\")==1),                  lit(\"NICU\")).otherwise(lit(\"Normal Newborn\")))        .with_column(\"CONTRACT\",            when( (col(\"HAS_NICU_MSDRG\")==1) | (col(\"HAS_NICU_APRDRG\")==1),                  lit(\"DRG\")).otherwise(lit(\"Per-Diem\")))        .with_column_renamed(\"BIRTH_TYPE\", \"EP_BIRTH_TYPE\")    )\n",
        "    \n",
        "    # 5) DELIVERY_DT = earliest service date per INDV_ID (same as Pandas transform('min'))\n",
        "    w_key = Window.partition_by(\"INDV_ID\").order_by(col(\"SVC_DATE\").asc())\n",
        "    newborns = newborns.with_column(\"DELIVERY_DT\", first_value(\"SVC_DATE\").over(w_key))\n",
        "    \n",
        "    # 6) Join back to all claims on INDV_ID (left), like your Pandas merge    \n",
        "    joined = (newborns.select(\"INDV_ID\", \"EP_BIRTH_TYPE\", \"DELIVERY_DT\", \"IN_DAYS\", \"BABY_TYPE\", \"CONTRACT\")              .join(c, \"INDV_ID\", \"left\"))\n",
        "    \n",
        "    # 7) Filter claims to on/after delivery date\n",
        "    newborn_claims = joined.filter(col(\"SRVC_FROM_DT\") >= col(\"DELIVERY_DT\"))\n",
        "    \n",
        "    # 8) Optional: high-cost flag (keep only if it\u2019s actually part of business rules)\n",
        "    newborn_claims = newborn_claims.with_column(\"HIGH_COST\", col(\"NET_PD_AMT\") > lit(HIGH_COST_CLAIM_THRESHOLD))\n",
        "    \n",
        "    return newborns, newborn_claims\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hospital Rollup and Episode Building\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_hosp_rollup(claims_df, runout_end):\n",
        "    \"\"\"\n",
        "    Recreates the original newborn hospital stay rollup in Snowpark.\n",
        "\n",
        "    Requirements implemented:\n",
        "    - filter: ~HIGH_COST (if column exists), CLAIM_TYPE == 'IP',\n",
        "              and (ADMIT_DT >= DELIVERY_DT) OR (SRVC_FROM_DT >= DELIVERY_DT)\n",
        "    - fill ADMIT_DT/DISCH_DT from SRVC_FROM_DT/SRVC_THRU_DT if null\n",
        "    - stitch stays per member with a new stay when gap > 4 days\n",
        "    - stay-level ADMIT = min admit, DSCHRG = max discharge, sum NET_PD_AMT\n",
        "    - clip DSCHRG to runout_end; flag OUT_END_DATE\n",
        "    - ADMIT = max(ADMIT, DELIVERY_DT)\n",
        "    - LOS = days between ADMIT and DSCHRG; if equal, LOS = 1; keep LOS >= 1\n",
        "    \"\"\"\n",
        "    # 1) Fill missing dates\n",
        "    c = (claims_df\n",
        "         .with_column(\"ADMIT_DT_FIL\", coalesce(col(\"ADMIT_DT\"), col(\"SRVC_FROM_DT\")))\n",
        "         .with_column(\"DISCH_DT_FIL\", coalesce(col(\"DISCH_DT\"), col(\"SRVC_THRU_DT\")))\n",
        "         .with_column(\"ADMIT_DT_FIL\", col(\"ADMIT_DT_FIL\").cast(\"DATE\"))\n",
        "         .with_column(\"DISCH_DT_FIL\", col(\"DISCH_DT_FIL\").cast(\"DATE\"))\n",
        "         .with_column(\"DELIVERY_DT\",  col(\"DELIVERY_DT\").cast(\"DATE\")))\n",
        "    # 2) Core filter (uses 'IP' because assign_claim_type emits 'IP', not 'Inpatient')\n",
        "    base_filter = (\n",
        "        (col(\"CLAIM_TYPE\") == lit(\"IP\")) &\n",
        "        ((col(\"ADMIT_DT_FIL\") >= col(\"DELIVERY_DT\")) | (col(\"SRVC_FROM_DT\") >= col(\"DELIVERY_DT\")))\n",
        "    )\n",
        "    if \"HIGH_COST\" in c.columns:\n",
        "        c = c.filter(~col(\"HIGH_COST\") & base_filter)\n",
        "    else:\n",
        "        c = c.filter(base_filter)\n",
        "    # 3) Order + gap logic (new stay when previous discharge gap > 4 days)\n",
        "    w_sort = Window.partition_by(\"INDV_ID\", \"DELIVERY_DT\").order_by(col(\"ADMIT_DT_FIL\"), col(\"DISCH_DT_FIL\"))\n",
        "    prev_dis = lag(col(\"DISCH_DT_FIL\")).over(w_sort)\n",
        "    gap_days = datediff(\"day\", prev_dis, col(\"ADMIT_DT_FIL\"))\n",
        "    new_stay_flag = when(prev_dis.is_null() | (gap_days > lit(HOSP_STAY_GAP_DAYS)), lit(1)).otherwise(lit(0))\n",
        "    c = c.with_column(\"NEW_STAY\", new_stay_flag)\n",
        "    # Cumulative sum \u2192 HOSP_STAY number per INDV_ID + DELIVERY_DT\n",
        "    w_cume = Window.partition_by(\"INDV_ID\", \"DELIVERY_DT\").order_by(col(\"ADMIT_DT_FIL\"), col(\"DISCH_DT_FIL\")).rows_between(Window.UNBOUNDED_PRECEDING, Window.CURRENT_ROW)\n",
        "    c = c.with_column(\"HOSP_STAY\", ssum(col(\"NEW_STAY\")).over(w_cume))\n",
        "    # 4) Aggregate to stay level\n",
        "    stays = (c.group_by(\"INDV_ID\", \"DELIVERY_DT\", \"HOSP_STAY\")\n",
        "               .agg(\n",
        "                   smin(\"ADMIT_DT_FIL\").alias(\"ADMIT\"),\n",
        "                   smax(\"DISCH_DT_FIL\").alias(\"DSCHRG\"),\n",
        "                   ssum(\"NET_PD_AMT\").alias(\"PAID_AMT\")\n",
        "               ))\n",
        "    # 5) Clip to runout, floor to delivery date, compute LOS\n",
        "    stays = (\n",
        "        stays\n",
        "        .with_column(\"OUT_END_DATE\", (col(\"DSCHRG\") > lit(runout_end)).cast(\"int\"))\n",
        "        .with_column(\"DSCHRG\", least(col(\"DSCHRG\"), lit(runout_end)))\n",
        "        .with_column(\"ADMIT\", greatest(col(\"ADMIT\"), col(\"DELIVERY_DT\")))\n",
        "        .with_column(\"LOS_RAW\", datediff(\"day\", col(\"ADMIT\"), col(\"DSCHRG\")))\n",
        "        .with_column(\"LOS\", when(col(\"DSCHRG\") == col(\"ADMIT\"), lit(1)).otherwise(col(\"LOS_RAW\")))\n",
        "        .drop(\"LOS_RAW\")\n",
        "        .filter(col(\"LOS\") >= lit(1))\n",
        "    )\n",
        "    return stays  # equivalent to hosp_rollup_df (KEY\u2192INDV_ID in your pipeline)\n",
        "\n",
        "\n",
        "def build_newborn_and_nicu_ids(\n",
        "    claims_df,\n",
        "    hosp_rollup_df,\n",
        "    birth_window_start,\n",
        "    birth_window_mid,\n",
        "    init_hosp_threshold_days=INIT_HOSP_THRESHOLD_DAYS,\n",
        "    readmit_threshold_days=READMIT_THRESHOLD_DAYS\n",
        "):\n",
        "    \"\"\"\n",
        "    Build newborn and NICU identifiers from claims and hospital rollup data.\n",
        "\n",
        "    This function performs claim-level deduplication and creates episode-level\n",
        "    and newborn-level rollups with NICU identification.\n",
        "    \"\"\"\n",
        "    # 1) Join claims to episode windows (INDV_ID + DELIVERY_DT)\n",
        "    nh = (\n",
        "        claims_df\n",
        "        .join(\n",
        "            hosp_rollup_df.select(\"INDV_ID\", \"DELIVERY_DT\", \"ADMIT\", \"DSCHRG\", \"LOS\"),\n",
        "            [\"INDV_ID\", \"DELIVERY_DT\"],\n",
        "            \"inner\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 2) Core in\u2011window filter & optional high\u2011cost filter\n",
        "    base_filter = (col(\"ADMIT\") <= col(\"SRVC_FROM_DT\")) & (col(\"SRVC_FROM_DT\") <= col(\"DSCHRG\"))\n",
        "    nh = nh.filter(base_filter)\n",
        "\n",
        "    if \"HIGH_COST\" in nh.columns:\n",
        "        nh = nh.filter(~col(\"HIGH_COST\"))\n",
        "\n",
        "    # 3) Keep only the columns we actually need downstream (prevents accidental dup sources)\n",
        "    keep_cols = [\n",
        "        \"INDV_ID\", \"DELIVERY_DT\", \"ADMIT\", \"DSCHRG\", \"LOS\",\n",
        "        \"CLM_AUD_NBR\", \"SRVC_FROM_DT\", \"SRVC_THRU_DT\", \"ADMIT_DT\", \"DISCH_DT\", \"PROCESS_DT\",\n",
        "        \"NET_PD_AMT\", \"PROC_CD\", \"RVNU_CD\", \"DRG\",\n",
        "        \"DIAG_1_CD\", \"DIAG_2_CD\", \"DIAG_3_CD\", \"DIAG_4_CD\", \"DIAG_5_CD\",\n",
        "        \"PROC_1_CD\", \"PROC_2_CD\", \"PROC_3_CD\",\n",
        "        \"BUS_LINE_CD\",\n",
        "        \"PRDCT_CD\",     # later mapped to LOB if LOB missing\n",
        "        \"BTH_DT\",\n",
        "        \"BIRTH_TYPE\", \"BABY_TYPE\", \"CONTRACT\",\n",
        "        \"DSCHRG_STS\",\n",
        "        \"PROV_TIN\", \"PROV_FULL_NM\", \"PROV_STATE\"\n",
        "    ]\n",
        "    keep_cols = [c for c in keep_cols if c in nh.columns]\n",
        "    nh = nh.select(*[col(c) for c in keep_cols])\n",
        "\n",
        "    # 4) Episode metadata & study year\n",
        "    nh = (\n",
        "        nh\n",
        "        .with_column(\n",
        "            \"STAY_TYPE\",\n",
        "            when(col(\"LOS\") >= lit(LONG_STAY_THRESHOLD), lit(\"Long Stay\"))\n",
        "            .otherwise(lit(\"Short Stay\"))\n",
        "        )\n",
        "        .with_column(\"IN_DAYS\", col(\"ADMIT\") <= (col(\"DELIVERY_DT\") + lit(init_hosp_threshold_days)))\n",
        "        .with_column(\n",
        "            \"STUDY_YR\",\n",
        "            when(\n",
        "                (col(\"DELIVERY_DT\") >= lit(birth_window_start)) &\n",
        "                (col(\"DELIVERY_DT\") <  lit(birth_window_mid)),\n",
        "                lit(\"Previous\")\n",
        "            ).otherwise(lit(\"Current\"))\n",
        "        )\n",
        "        .with_column(\"ADMIT_GAP\", datediff(\"day\", col(\"DELIVERY_DT\"), col(\"ADMIT\")))\n",
        "        .filter((col(\"ADMIT_GAP\") < lit(readmit_threshold_days)) & col(\"IN_DAYS\"))\n",
        "    )\n",
        "\n",
        "    # 5) *** Claim\u2011level de\u2011dup per episode *** (prevents AMTPAID inflation)\n",
        "    # If a claim can appear multiple times in the joined set, pick ONE row per INDV_ID, DELIVERY_DT, CLAIMNO\n",
        "    # Prefer the latest service info within the episode.\n",
        "    w_claim = (\n",
        "        Window.partition_by(\"INDV_ID\", \"DELIVERY_DT\", \"CLM_AUD_NBR\")\n",
        "              .order_by(col(\"SRVC_THRU_DT\").desc_nulls_last(), col(\"SRVC_FROM_DT\").desc_nulls_last())\n",
        "    )\n",
        "\n",
        "    claim_base = (\n",
        "        nh.with_column(\"RN_CLAIM\", row_number().over(w_claim))\n",
        "          .filter(col(\"RN_CLAIM\") == 1)\n",
        "          .drop(\"RN_CLAIM\")\n",
        "    )\n",
        "\n",
        "    # Map PRODUCT\u2192LOB if LOB not present\n",
        "    if \"LOB\" not in claim_base.columns and \"PRDCT_CD\" in claim_base.columns:\n",
        "        claim_base = claim_base.with_column(\"LOB\", col(\"PRDCT_CD\"))\n",
        "\n",
        "    # 6) Episode\u2011level rollup from the de\u2011duped claims only\n",
        "    grp_ep = [\n",
        "        \"INDV_ID\", \"BTH_DT\", \"DELIVERY_DT\", \"ADMIT\", \"DSCHRG\", \"LOS\",\n",
        "        \"STAY_TYPE\", \"BIRTH_TYPE\", \"CONTRACT\", \"BUS_LINE_CD\", \"LOB\", \"STUDY_YR\"\n",
        "    ]\n",
        "    grp_ep = [g for g in grp_ep if g in claim_base.columns]\n",
        "\n",
        "    newborn_ident_ep = (\n",
        "        claim_base.group_by(*grp_ep)\n",
        "                  .agg(\n",
        "                      ssum(\"NET_PD_AMT\").alias(\"NET_PD_AMT\"),\n",
        "                      # BABY_TYPE/CONTRACT should be constant within an episode; if not, pick a stable representative:\n",
        "                      smin(\"BABY_TYPE\").alias(\"BABY_TYPE\")\n",
        "                  )\n",
        "    )\n",
        "\n",
        "    # 7) Newborn\u2011level rollup (one row per INDV_ID + DELIVERY_DT)\n",
        "    # Collapse multiple episodes (if any) and derive final fields. AMTPAID remains correct because\n",
        "    # each episode was built from de\u2011duped claims.\n",
        "    newborn_ident_df = (\n",
        "        newborn_ident_ep\n",
        "        .group_by(\"INDV_ID\", \"BTH_DT\", \"DELIVERY_DT\", \"BUS_LINE_CD\", \"LOB\", \"STUDY_YR\", \"STAY_TYPE\")\n",
        "        .agg(\n",
        "            smin(\"ADMIT\").alias(\"ADMIT\"),\n",
        "            smax(\"DSCHRG\").alias(\"DSCHRG\"),\n",
        "            ssum(\"NET_PD_AMT\").alias(\"NET_PD_AMT\"),\n",
        "            # Any NICU inside the newborn \u21d2 NICU\n",
        "            smax(when(col(\"BABY_TYPE\") == lit(\"NICU\"), lit(1)).otherwise(lit(0))).alias(\"ANY_NICU\"),\n",
        "            # Birth type priority: Multiple > Twin > Single > Unknown\n",
        "            smax(\n",
        "                when(col(\"BIRTH_TYPE\") == lit(\"Multiple\"), lit(3))\n",
        "                .when(col(\"BIRTH_TYPE\") == lit(\"Twin\"),     lit(2))\n",
        "                .when(col(\"BIRTH_TYPE\") == lit(\"Single\"),   lit(1))\n",
        "                .otherwise(lit(0))\n",
        "            ).alias(\"BT_PRI\"),\n",
        "            # Contract priority: if any episode is DRG \u21d2 DRG\n",
        "            smax(when(col(\"CONTRACT\") == lit(\"DRG\"), lit(1)).otherwise(lit(0))).alias(\"ANY_DRG\")\n",
        "        )\n",
        "        .with_column(\"LOS_RAW\", datediff(\"day\", col(\"ADMIT\"), col(\"DSCHRG\")))\n",
        "        .with_column(\"LOS\", when(col(\"DSCHRG\") == col(\"ADMIT\"), lit(1)).otherwise(col(\"LOS_RAW\")))\n",
        "        .drop(\"LOS_RAW\")\n",
        "        .with_column(\n",
        "            \"BABY_TYPE\",\n",
        "            when(col(\"ANY_NICU\") == lit(1), lit(\"NICU\")).otherwise(lit(\"Normal Newborn\"))\n",
        "        )\n",
        "        .with_column(\n",
        "            \"BIRTH_TYPE\",\n",
        "            when(col(\"BT_PRI\") == lit(3), lit(\"Multiple\"))\n",
        "            .when(col(\"BT_PRI\") == lit(2), lit(\"Twin\"))\n",
        "            .when(col(\"BT_PRI\") == lit(1), lit(\"Single\"))\n",
        "            .otherwise(lit(\"Unknown\"))\n",
        "        )\n",
        "        .with_column(\n",
        "            \"CONTRACT\",\n",
        "            when(col(\"ANY_DRG\") == lit(1), lit(\"DRG\")).otherwise(lit(\"Per-Diem\"))\n",
        "        )\n",
        "        .drop(\"ANY_NICU\", \"BT_PRI\", \"ANY_DRG\")\n",
        "    )\n",
        "\n",
        "    # 8) NICU subset (one row per newborn)\n",
        "    nicu_ident = (\n",
        "        newborn_ident_df\n",
        "        .filter(col(\"BABY_TYPE\") == lit(\"NICU\"))\n",
        "        .with_column_renamed(\"NET_PD_AMT\", \"TOTAL_NICU_COST\")\n",
        "    )\n",
        "\n",
        "    # 9) Build nicu_claims_df from the de\u2011duped claim_base to avoid any row blow\u2011up\n",
        "    claim_cols = [\n",
        "        \"INDV_ID\", \"CLM_AUD_NBR\", \"SRVC_FROM_DT\", \"SRVC_THRU_DT\", \"ADMIT_DT\", \"DISCH_DT\",\n",
        "        \"PROV_TIN\", \"PROC_CD\", \"RVNU_CD\", \"DRG\", \"DSCHRG_STS\", \"NET_PD_AMT\",\n",
        "        \"DIAG_1_CD\", \"DIAG_2_CD\", \"DIAG_3_CD\", \"DIAG_4_CD\", \"DIAG_5_CD\", \"PROC_1_CD\", \"PROC_2_CD\", \"PROC_3_CD\"\n",
        "    ]\n",
        "    claim_cols = [c for c in claim_cols if c in claim_base.columns]\n",
        "\n",
        "    # LOS comes only from rollup path\n",
        "    nicu_claims_df = (\n",
        "        claim_base.select(*claim_cols, \"DELIVERY_DT\", \"LOS\")\n",
        "                  .join(nicu_ident.select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\"), [\"INDV_ID\"], \"inner\")\n",
        "                  .filter((col(\"SRVC_FROM_DT\") >= col(\"ADMIT\")) & (col(\"SRVC_FROM_DT\") <= col(\"DSCHRG\")))\n",
        "    )\n",
        "\n",
        "    # 10) LAST_DISCHARGE_STATUS\n",
        "    order_col = (\n",
        "        when(col(\"DSCHRG_STS\") == lit(\"20\"), lit(0))\n",
        "        .when(col(\"DSCHRG_STS\") == lit(\"07\"), lit(1))\n",
        "        .when(col(\"DSCHRG_STS\").isin([\"02\", \"05\", \"66\", \"43\", \"62\", \"63\", \"65\"]), lit(2))\n",
        "        .when(col(\"DSCHRG_STS\") == lit(\"30\"), lit(3))\n",
        "        .when(col(\"DSCHRG_STS\").isin([\"01\", \"06\"]), lit(4))\n",
        "        .when(\n",
        "            (length(col(\"DSCHRG_STS\")) < lit(2)) |\n",
        "            (col(\"DSCHRG_STS\").isin([\"04\", \"41\", \"50\", \"51\", \"70\", \"03\", \"64\"])) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"08\"), lit(\"19\"))) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"21\"), lit(\"29\"))) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"31\"), lit(\"39\"))) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"44\"), lit(\"49\"))) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"52\"), lit(\"60\"))) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"67\"), lit(\"69\"))) |\n",
        "            (col(\"DSCHRG_STS\").between(lit(\"71\"), lit(\"99\"))),\n",
        "            lit(6)\n",
        "        ).otherwise(lit(9))\n",
        "    )\n",
        "\n",
        "    ranked = (\n",
        "        nicu_claims_df\n",
        "        .filter((col(\"DSCHRG_STS\") != lit(\"00\")) | col(\"DSCHRG_STS\").is_not_null())\n",
        "        .with_column(\"ORDER\", order_col)\n",
        "        .with_column(\n",
        "            \"RN\",\n",
        "            row_number().over(\n",
        "                Window.partition_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "                      .order_by(\n",
        "                          col(\"ORDER\").asc(),\n",
        "                          col(\"DISCH_DT\").desc(),\n",
        "                          col(\"SRVC_FROM_DT\").desc(),\n",
        "                          col(\"DSCHRG_STS\").asc()\n",
        "                      )\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    last_status = (\n",
        "        ranked.filter(col(\"RN\") == 1)\n",
        "              .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", col(\"DSCHRG_STS\").alias(\"LAST_DISCHARGE_STATUS\"))\n",
        "    )\n",
        "\n",
        "    nicu_claims_df = nicu_claims_df.join(last_status, [\"INDV_ID\", \"ADMIT\", \"DSCHRG\"], \"left\")\n",
        "\n",
        "    # 11) Discharge provider attribution (episode \u00d7 provider) using de\u2011duped claims\n",
        "    if all(x in nicu_claims_df.columns for x in [\"NET_PD_AMT\", \"ADMIT_DT\", \"DISCH_DT\", \"PROV_TIN\"]):\n",
        "        ep = (\n",
        "            nicu_claims_df\n",
        "            .filter(col(\"PROV_TIN\").is_not_null())\n",
        "            .group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"DELIVERY_DT\", \"LOS\", \"PROV_TIN\")\n",
        "            .agg(\n",
        "                ssum(\"NET_PD_AMT\").alias(\"HOSPPAID\"),\n",
        "                smin(\"ADMIT_DT\").alias(\"HOSPADMIT\"),\n",
        "                smax(\"DISCH_DT\").alias(\"HOSPDISCHG\")\n",
        "            )\n",
        "            .with_column(\n",
        "                \"HOSPLOS\",\n",
        "                when(\n",
        "                    col(\"HOSPDISCHG\") == col(\"DSCHRG\"),\n",
        "                    datediff(\"day\", col(\"HOSPADMIT\"), col(\"HOSPDISCHG\"))\n",
        "                )\n",
        "                .otherwise(datediff(\"day\", col(\"HOSPADMIT\"), col(\"HOSPDISCHG\")) + lit(1))\n",
        "            )\n",
        "        )\n",
        "\n",
        "        w_best = (\n",
        "            Window.partition_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "                  .order_by(\n",
        "                      col(\"HOSPDISCHG\").desc(),\n",
        "                      col(\"HOSPLOS\").desc(),\n",
        "                      col(\"HOSPPAID\").desc()\n",
        "                  )\n",
        "        )\n",
        "\n",
        "        best = ep.with_column(\"RN\", row_number().over(w_best)).filter(col(\"RN\") == 1).drop(\"RN\")\n",
        "\n",
        "        hosplist = (\n",
        "            claims_df.select(\"PROV_TIN\", \"PROV_FULL_NM\", \"PROV_STATE\")\n",
        "                     .filter(col(\"PROV_TIN\").is_not_null())\n",
        "                     .distinct()\n",
        "        )\n",
        "\n",
        "        nicu_dischg_provider = (\n",
        "            best.join(hosplist, [\"PROV_TIN\"], \"left\")\n",
        "                .with_column(\"PROV_FULL_NM\", coalesce(col(\"PROV_FULL_NM\"), lit(\"Unknown\")))\n",
        "                .with_column(\"PROV_STATE\",   coalesce(col(\"PROV_STATE\"),   lit(\"Unknown\")))\n",
        "        )\n",
        "    else:\n",
        "        nicu_dischg_provider = None\n",
        "\n",
        "    # 12) REV & DRG episode features (computed from de\u2011duped claims only, so stable)\n",
        "    rev_ep = (\n",
        "        nicu_claims_df\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"RVNU_CD\")\n",
        "        .with_column(\"REV_NUM\", sql_expr(\"TRY_TO_NUMBER(RVNU_CD)\"))\n",
        "        .filter(col(\"REV_NUM\").between(*NICU_REV_CODE_RANGE))\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"REV_NUM\")\n",
        "        .distinct()\n",
        "    )\n",
        "\n",
        "    rev_min = (\n",
        "        rev_ep.group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "              .agg(smin(\"REV_NUM\").alias(\"FINAL_REV_NUM\"))\n",
        "              .with_column(\"FINAL_REV_CD\", sql_expr(\"TO_VARCHAR(FINAL_REV_NUM)\"))\n",
        "              .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"FINAL_REV_CD\")\n",
        "    )\n",
        "\n",
        "    w_rev = Window.partition_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\").order_by(col(\"REV_NUM\").asc())\n",
        "\n",
        "    rev_second = (\n",
        "        rev_ep.with_column(\"RN\", row_number().over(w_rev))\n",
        "              .filter(col(\"RN\") == 2)\n",
        "              .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", col(\"REV_NUM\").alias(\"REV_NUM_2\"))\n",
        "    )\n",
        "\n",
        "    rev_features = (\n",
        "        rev_min.join(rev_second, [\"INDV_ID\", \"ADMIT\", \"DSCHRG\"], \"left\")\n",
        "               .with_column(\"REV_LEVELING\", col(\"REV_NUM_2\").is_not_null())\n",
        "               .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"FINAL_REV_CD\", \"REV_LEVELING\")\n",
        "    )\n",
        "\n",
        "    drg_ep = (\n",
        "        nicu_claims_df\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"DRG\")\n",
        "        .with_column(\"DRG_NUM\", sql_expr(\"TRY_TO_NUMBER(DRG)\"))\n",
        "        .filter(\n",
        "            (col(\"DRG_NUM\").between(*NICU_MS_DRG_RANGE)) |\n",
        "            (col(\"DRG_NUM\").between(*NICU_APR_DRG_RANGE))\n",
        "        )\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"DRG_NUM\")\n",
        "        .distinct()\n",
        "    )\n",
        "\n",
        "    drg_min = (\n",
        "        drg_ep.group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "              .agg(smin(\"DRG_NUM\").alias(\"FINAL_DRG_NUM\"))\n",
        "              .with_column(\"FINAL_DRG_CD\", sql_expr(\"TO_VARCHAR(FINAL_DRG_NUM)\"))\n",
        "              .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"FINAL_DRG_CD\")\n",
        "    )\n",
        "\n",
        "    # 13) Episode features joined to newborn_ident_ep (episode\u2011level) or newborn_ident_df (newborn\u2011level)\n",
        "    ep_with_rev = newborn_ident_ep.join(rev_features, [\"INDV_ID\", \"ADMIT\", \"DSCHRG\"], \"left\")\n",
        "\n",
        "    ep_with_drg = (\n",
        "        ep_with_rev.join(drg_min, [\"INDV_ID\", \"ADMIT\", \"DSCHRG\"], \"left\")\n",
        "                   .with_column(\"FINAL_DRG_CD\", sql_expr(\"IFF(CONTRACT='DERIV_DRG_CD', FINAL_DRG_CD, NULL)\"))\n",
        "    )\n",
        "\n",
        "    # Outputs\n",
        "    return {\n",
        "        \"newborn_hosp_clms\": claim_base,         # claims limited to episode window, de\u2011duped by claim\n",
        "        \"newborn_ident_df\": newborn_ident_df,    # one row per newborn (INDV_ID + DELIVERY_DT)\n",
        "        \"nicu_ident\": nicu_ident,                # subset of newborn_ident_df\n",
        "        \"nicu_claims_df\": nicu_claims_df,        # claims within NICU newborn stay, de\u2011duped\n",
        "        \"nicu_dischg_provider\": nicu_dischg_provider,\n",
        "        \"rev_out\": rev_features,                  # episode + REV features\n",
        "        \"drg_out\": drg_min                        # episode + REV + DRG features\n",
        "    }\n",
        "\n",
        "\n",
        "# --- 1) Professional fees (all, manageable CPT set, critical care set) ---\n",
        "def _prof_fee_aggregates(nicu_claims_df):\n",
        "    \"\"\"Calculate professional fee aggregates from NICU claims.\"\"\"\n",
        "    # Only professional claims (CPT present)\n",
        "    prof = (\n",
        "        nicu_claims_df.filter(col(\"PROC_CD\").is_not_null())\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"LOS\", \"SRVC_FROM_DT\", \"PROC_CD\", \"NET_PD_AMT\", \"ADMIT_DT\", \"DISCH_DT\")\n",
        "    )\n",
        "\n",
        "    # All professional fees\n",
        "    all_prof = (\n",
        "        prof.group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "            .agg(ssum(\"NET_PD_AMT\").alias(\"ALL_PROFFEE\"))\n",
        "    )\n",
        "\n",
        "    # Manageable CPT set\n",
        "    manageable = MANAGEABLE_CPT_CODES\n",
        "    man = prof.filter(col(\"PROC_CD\").isin(manageable))\n",
        "\n",
        "    # Unique service-days counted per (INDV_ID, ADMIT, DSCHRG) & CPT & FROMDATE\n",
        "    # Equivalent to nunique(KEY-ADMIT-DSCHRG-FROMDATE-CPT) in Pandas\n",
        "    man_days_key = concat(\n",
        "        col(\"INDV_ID\").cast(\"string\"), lit(\"-\"),\n",
        "        to_char(col(\"ADMIT\"), \"YYYY-MM-DD\"), lit(\"-\"),\n",
        "        to_char(col(\"DSCHRG\"), \"YYYY-MM-DD\"), lit(\"-\"),\n",
        "        to_char(col(\"SRVC_FROM_DT\"), \"YYYY-MM-DD\"), lit(\"-\"),\n",
        "        col(\"PROC_CD\")\n",
        "    )\n",
        "\n",
        "    man_aggs = (\n",
        "        man.with_column(\"CPT_DAYS_KEY\", man_days_key)\n",
        "           .group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "           .agg(\n",
        "               ssum(\"NET_PD_AMT\").alias(\"MANAGEABLE_PROFFEE\"),\n",
        "               count_distinct(\"CPT_DAYS_KEY\").alias(\"MANAGEABLE_SVC_DAYS\")\n",
        "           )\n",
        "    )\n",
        "\n",
        "    # Critical care CPT set\n",
        "    critical = CRITICAL_CARE_CPT_CODES\n",
        "    crit = prof.filter(col(\"PROC_CD\").isin(critical))\n",
        "\n",
        "    crit_days_key = concat(\n",
        "        col(\"INDV_ID\").cast(\"string\"), lit(\"-\"),\n",
        "        to_char(col(\"ADMIT\"), \"YYYY-MM-DD\"), lit(\"-\"),\n",
        "        to_char(col(\"DSCHRG\"), \"YYYY-MM-DD\"), lit(\"-\"),\n",
        "        to_char(col(\"SRVC_FROM_DT\"), \"YYYY-MM-DD\")\n",
        "    )\n",
        "\n",
        "    crit_aggs = (\n",
        "        crit.with_column(\"CRITICAL_DAYS_KEY\", crit_days_key)\n",
        "            .group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "            .agg(\n",
        "                ssum(\"NET_PD_AMT\").alias(\"CRITICAL_CARE_PROFFEE\"),\n",
        "                count_distinct(\"CRITICAL_DAYS_KEY\").alias(\"CRITICAL_CARE_DAYS\")\n",
        "            )\n",
        "    )\n",
        "\n",
        "    return all_prof, man_aggs, crit_aggs\n",
        "\n",
        "\n",
        "# --- 2) Room & Board (REV 011\u2013017,020) w/ CPT null ---\n",
        "def _room_and_board(nicu_claims_df):\n",
        "    \"\"\"Calculate room and board costs from NICU claims.\"\"\"\n",
        "    rb_prefix_ok = substring(col(\"RVNU_CD\"), 1, 3).isin(ROOM_BOARD_REV_PREFIXES)\n",
        "\n",
        "    room = (\n",
        "        nicu_claims_df\n",
        "        .filter(rb_prefix_ok & col(\"PROC_CD\").is_null())\n",
        "        .group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "        .agg(ssum(\"NET_PD_AMT\").alias(\"FACILITY_RM_COST\"))\n",
        "    )\n",
        "\n",
        "    return room\n",
        "\n",
        "\n",
        "# --- 3) Readmissions (next episode within 30 days) ---\n",
        "def _readmissions(nicu_ident, hosp_rollup_df):\n",
        "    \"\"\"\n",
        "    Identify readmissions within 30 days of NICU discharge.\n",
        "\n",
        "    Args:\n",
        "        nicu_ident: episode-level (INDV_ID, ADMIT, DSCHRG, ... TOTAL_NICU_COST, LOS, etc.)\n",
        "        hosp_rollup_df: (INDV_ID, DELIVERY_DT, HOSP_STAY, ADMIT, DSCHRG, PAID_AMT, LOS, ...)\n",
        "    \"\"\"\n",
        "    future = (\n",
        "        hosp_rollup_df\n",
        "        .select(\n",
        "            col(\"INDV_ID\"),\n",
        "            col(\"ADMIT\").alias(\"READMIT_DT\"),\n",
        "            col(\"PAID_AMT\").alias(\"READMIT_PAID_AMT\"),\n",
        "            col(\"LOS\").alias(\"READMIT_LOS\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # join and keep when READMIT_DT in (DSCHRG+1, DSCHRG+30]\n",
        "    j = (\n",
        "        nicu_ident.select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "        .join(future, [\"INDV_ID\"], \"inner\")\n",
        "        .filter(\n",
        "            (col(\"READMIT_DT\") > col(\"DSCHRG\")) &\n",
        "            (datediff(\"day\", col(\"DSCHRG\"), col(\"READMIT_DT\")) <= lit(30))\n",
        "        )\n",
        "    )\n",
        "\n",
        "    readm = (\n",
        "        j.group_by(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "         .agg(\n",
        "             count_distinct(\"READMIT_DT\").alias(\"READMIT\"),\n",
        "             ssum(\"READMIT_PAID_AMT\").alias(\"READMIT_PAID_AMT\"),\n",
        "             ssum(\"READMIT_LOS\").alias(\"READMIT_LOS\")\n",
        "         )\n",
        "    )\n",
        "\n",
        "    return readm\n",
        "\n",
        "\n",
        "# --- 4) \"Unpivot\" DIAG/PROC columns using unions (Snowpark lacks UNPIVOT API) ---\n",
        "def _union_diag_proc(nicu_claims_df):\n",
        "    \"\"\"Unpivot diagnosis and procedure columns using unions.\"\"\"\n",
        "    diag_cols = [c for c in nicu_claims_df.columns if c.upper().startswith(\"DIAG\")]\n",
        "    proc_cols = [c for c in nicu_claims_df.columns if c.upper().startswith(\"PROC\")]\n",
        "\n",
        "    # DIAGTMP rows\n",
        "    diag_parts = []\n",
        "    for d in diag_cols:\n",
        "        diag_parts.append(\n",
        "            nicu_claims_df.select(\n",
        "                col(\"INDV_ID\"), col(\"ADMIT\"), col(\"DSCHRG\"),\n",
        "                col(d).alias(\"DIAGTMP\")\n",
        "            ).filter(col(\"DIAGTMP\").is_not_null())\n",
        "        )\n",
        "\n",
        "    diag_tmp = None\n",
        "    for p in diag_parts:\n",
        "        diag_tmp = p if diag_tmp is None else diag_tmp.union_all(p)\n",
        "\n",
        "    if diag_tmp is None:\n",
        "        diag_tmp = nicu_claims_df.session.create_dataframe([], schema=[\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"DIAGTMP\"])\n",
        "\n",
        "    # PROCTMP rows\n",
        "    proc_parts = []\n",
        "    for pr in proc_cols:\n",
        "        proc_parts.append(\n",
        "            nicu_claims_df.select(\n",
        "                col(\"INDV_ID\"), col(\"ADMIT\"), col(\"DSCHRG\"),\n",
        "                col(pr).alias(\"PROCTMP\")\n",
        "            ).filter(col(\"PROCTMP\").is_not_null())\n",
        "        )\n",
        "\n",
        "    proc_tmp = None\n",
        "    for p in proc_parts:\n",
        "        proc_tmp = p if proc_tmp is None else proc_tmp.union_all(p)\n",
        "\n",
        "    if proc_tmp is None:\n",
        "        proc_tmp = nicu_claims_df.session.create_dataframe([], schema=[\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"PROCTMP\"])\n",
        "\n",
        "    # de-dup\n",
        "    diag_tmp = diag_tmp.distinct()\n",
        "    proc_tmp = proc_tmp.distinct()\n",
        "\n",
        "    return diag_tmp, proc_tmp\n",
        "\n",
        "\n",
        "# --- 5) Birthweight / Gestational age / NAS via REF tables ---\n",
        "def _bw_ga_nas(session, diag_tmp):\n",
        "    \"\"\"\n",
        "    Extract birthweight, gestational age, and NAS flags from diagnosis codes.\n",
        "\n",
        "    Uses reference tables with CODE -> category mapping.\n",
        "    Adjust the table/column names if your REF schemas differ.\n",
        "    \"\"\"\n",
        "    bw_ref = session.table(\"SUPP_DATA.REF_BIRTHWEIGHT_ICD\").select(\n",
        "        col(\"CODE\").alias(\"ICD_CODE\"),\n",
        "        col(\"DESCRIPTION\").alias(\"BW_CAT\")\n",
        "    )\n",
        "    ga_ref = session.table(\"SUPP_DATA.REF_GEST_AGE_ICD\").select(\n",
        "        col(\"CODE\").alias(\"ICD_CODE\"),\n",
        "        col(\"DESCRIPTION\").alias(\"GA_CAT\")\n",
        "    )\n",
        "\n",
        "    # Birthweight (first category per INDV_ID by lexical order)\n",
        "    bw = (\n",
        "        diag_tmp.join(bw_ref, diag_tmp[\"DIAGTMP\"] == bw_ref[\"ICD_CODE\"], \"inner\")\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"BW_CAT\")\n",
        "    )\n",
        "\n",
        "    # Pick one BW_CAT per INDV_ID (if you want per episode, include ADMIT/DSCHRG in the window)\n",
        "    w_bw = Window.partition_by(\"INDV_ID\").order_by(col(\"BW_CAT\").asc())\n",
        "    bw = (\n",
        "        bw.with_column(\"RN\", row_number().over(w_bw))\n",
        "          .filter(col(\"RN\") == 1)\n",
        "          .drop(\"RN\")\n",
        "    )\n",
        "\n",
        "    # Gestational age\n",
        "    ga = (\n",
        "        diag_tmp.join(ga_ref, diag_tmp[\"DIAGTMP\"] == ga_ref[\"ICD_CODE\"], \"inner\")\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\", \"GA_CAT\")\n",
        "    )\n",
        "\n",
        "    w_ga = Window.partition_by(\"INDV_ID\").order_by(col(\"GA_CAT\").asc())\n",
        "    ga = (\n",
        "        ga.with_column(\"RN\", row_number().over(w_ga))\n",
        "          .filter(col(\"RN\") == 1)\n",
        "          .drop(\"RN\")\n",
        "    )\n",
        "\n",
        "    # NAS flag (ICD-10 code \"P96.1\"; your data used \"P961\" \u2013 keep the exact string that appears in claims)\n",
        "    nas = (\n",
        "        diag_tmp.filter(col(\"DIAGTMP\") == lit(\"P961\"))\n",
        "        .select(\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "        .with_column(\"NAS\", lit(True))\n",
        "        .distinct()\n",
        "    )\n",
        "\n",
        "    return bw, ga, nas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NICU Analysis and Rollup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_nicu_rollup(\n",
        "    session,\n",
        "    # from prior steps\n",
        "    nicu_ident,            # episode-level NICU babies (INDV_ID, ADMIT, DSCHRG, LOS, TOTAL_NICU_COST, CONTRACT, etc.)\n",
        "    nicu_claims_df,        # claim-level subset bounded to NICU episodes\n",
        "    hosp_rollup_df,        # episode stays (INDV_ID, DELIVERY_DT, HOSP_STAY, ADMIT, DSCHRG, PAID_AMT, LOS)\n",
        "    rev_out,               # episode-level REV features: (INDV_ID, ADMIT, DSCHRG, FINAL_REV_CD, REV_LEVELING)\n",
        "    drg_out,               # episode-level DRG features: (INDV_ID, ADMIT, DSCHRG, FINAL_DRG_CD)\n",
        "    nicu_dischg_provider   # episode-level provider attribution\n",
        "):\n",
        "    \"\"\"\n",
        "    Build NICU rollup with all clinical and financial features.\n",
        "\n",
        "    Aggregates professional fees, room & board, readmissions, and clinical\n",
        "    indicators for NICU episodes.\n",
        "    \"\"\"\n",
        "    # 1) prof fee rollups\n",
        "    all_prof, man_aggs, crit_aggs = _prof_fee_aggregates(nicu_claims_df)\n",
        "\n",
        "    # 2) room & board\n",
        "    room = _room_and_board(nicu_claims_df)\n",
        "\n",
        "    # 3) readmissions\n",
        "    readm = _readmissions(nicu_ident, hosp_rollup_df)\n",
        "\n",
        "    # 4) diag/proc \"unpivot\"\n",
        "    diag_tmp, proc_tmp = _union_diag_proc(nicu_claims_df)\n",
        "\n",
        "    # 5) birthweight / gest age / NAS via REF tables\n",
        "    bw, ga, nas = _bw_ga_nas(session, diag_tmp)\n",
        "\n",
        "    # Start from episode-level NICU set\n",
        "    base = nicu_ident\n",
        "\n",
        "    # Left-join all features on (INDV_ID, ADMIT, DSCHRG)\n",
        "    keys = (\"INDV_ID\", \"ADMIT\", \"DSCHRG\")\n",
        "\n",
        "    out = (\n",
        "        base\n",
        "        .join(all_prof.select(*keys, \"ALL_PROFFEE\"), keys, \"left\")\n",
        "        .join(man_aggs.select(*keys, \"MANAGEABLE_PROFFEE\"), keys, \"left\")\n",
        "        .join(crit_aggs.select(*keys, \"CRITICAL_CARE_PROFFEE\"), keys, \"left\")\n",
        "        .join(room.select(*keys, \"FACILITY_RM_COST\"), keys, \"left\")\n",
        "        .join(readm.select(*keys, \"READMIT\", \"READMIT_PAID_AMT\", \"READMIT_LOS\"), keys, \"left\")\n",
        "        .join(nas.select(*keys, \"NAS\"), keys, \"left\")\n",
        "        .join(ga.select(*keys, \"GA_CAT\"), keys, \"left\")\n",
        "        .join(bw.select(*keys, \"BW_CAT\"), keys, \"left\")\n",
        "        .join(rev_out, keys, \"left\")\n",
        "        .join(drg_out, keys, \"left\")\n",
        "    )\n",
        "\n",
        "    if nicu_dischg_provider is not None:\n",
        "        out = (\n",
        "            out.join(\n",
        "                nicu_dischg_provider.select(*keys, \"PROV_TIN\", \"PROV_FULL_NM\", \"PROV_STATE\"),\n",
        "                keys, \"left\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # 6) derived rollup metrics\n",
        "    out = (\n",
        "        out\n",
        "        .with_column(\"ALL_PROFFEE\",        coalesce(col(\"ALL_PROFFEE\"), lit(0)))\n",
        "        .with_column(\"MANAGEABLE_PROFFEE\", coalesce(col(\"MANAGEABLE_PROFFEE\"), lit(0)))\n",
        "        .with_column(\"CRITICAL_CARE_PROFFEE\", coalesce(col(\"CRITICAL_CARE_PROFFEE\"), lit(0)))\n",
        "        .with_column(\"FACILITY_RM_COST\",   coalesce(col(\"FACILITY_RM_COST\"), lit(0)))\n",
        "        .with_column(\"TOTAL_NICU_COST\",    coalesce(col(\"TOTAL_NICU_COST\"), lit(0)))\n",
        "        .with_column(\"LOS\",                coalesce(col(\"LOS\"), lit(0)))\n",
        "        .with_column(\"ALL_FACILITY_COST\",  col(\"TOTAL_NICU_COST\") - col(\"ALL_PROFFEE\"))\n",
        "        .with_column(\n",
        "            \"LOW_PAID_NICU\",\n",
        "            when(\n",
        "                (col(\"LOS\") > lit(0)) &\n",
        "                ((col(\"TOTAL_NICU_COST\") / col(\"LOS\")) < lit(NICU_LOW_COST_PER_DAY_THRESHOLD)),\n",
        "                lit(True)\n",
        "            ).otherwise(lit(False))\n",
        "        )\n",
        "        .with_column(\n",
        "            \"INAPPROPRIATE_NICU\",\n",
        "            (col(\"CONTRACT\") == lit(\"DRG\")) &\n",
        "            (col(\"LOS\") <= lit(INAPPROPRIATE_NICU_MAX_LOS)) &\n",
        "            col(\"FINAL_REV_CD\").isin([\"170\", \"171\"])\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Export Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_final_export(newborn_df, nicu_df):\n",
        "    \"\"\"Prepare final export by joining newborn and NICU dataframes.\"\"\"\n",
        "    join_keys = ['INDV_ID', 'ADMIT', 'DSCHRG']\n",
        "    left_cols = set(newborn_df.columns)\n",
        "    right_cols = [c for c in nicu_df.columns if c not in join_keys and c not in left_cols]\n",
        "\n",
        "    nicu_df_trimmed = nicu_df.select(\n",
        "        *[col(k) for k in join_keys],\n",
        "        *[col(c) for c in right_cols]\n",
        "    )\n",
        "\n",
        "    newborns_out = newborn_df.join(nicu_df_trimmed, join_keys, \"left\")\n",
        "    # Calculate cost per day (NET_PD_AMT / LOS)\n",
        "    newborns_out = newborns_out.with_column(\n",
        "        \"COST_PER_DAY\",\n",
        "        when(col(\"LOS\") > lit(0), col(\"NET_PD_AMT\") / col(\"LOS\"))\n",
        "        .otherwise(lit(None))\n",
        "    )\n",
        "    \n",
        "    return newborns_out\n",
        "\n",
        "\n",
        "def export_to_snowflake(df, table_name):\n",
        "    \"\"\"\n",
        "    Write DataFrame to Snowflake table.\n",
        "\n",
        "    Args:\n",
        "        df: Snowpark DataFrame to export\n",
        "        table_name: Fully qualified table name\n",
        "\n",
        "    Note:\n",
        "        Respects DRY_RUN configuration - will only preview data if DRY_RUN=True\n",
        "    \"\"\"\n",
        "    if DRY_RUN:\n",
        "        row_count = df.count()\n",
        "        logger.info(f\"[DRY-RUN] Would export {row_count:,} rows to {table_name}\")\n",
        "        logger.info(f\"[DRY-RUN] Preview of first 5 rows:\")\n",
        "        df.show(5)\n",
        "        return\n",
        "\n",
        "    logger.info(f\"Exporting data to Snowflake table: {table_name}\")\n",
        "    df.write.mode(\"overwrite\").save_as_table(table_name)\n",
        "    logger.info(\"Export complete.\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Main pipeline\n",
        "# ---------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main Pipeline Orchestration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(auto_window=True):\n",
        "    \"\"\"Main NICU pipeline execution function.\"\"\"\n",
        "    logger.info(\"Starting NICU pipeline\")\n",
        "    session = get_snowflake_session()\n",
        "    client_data = CLIENT_DATA\n",
        "\n",
        "    if auto_window:\n",
        "        birth_window_start, birth_window_end, birth_window_mid, runout_end = calculate_birth_window(session, client_data)\n",
        "    else:\n",
        "        birth_window_start = pd.Timestamp(\"2021-01-01\")\n",
        "        birth_window_end = pd.Timestamp(\"2022-12-31\")\n",
        "        runout_end = pd.Timestamp(\"2023-03-31\")\n",
        "\n",
        "    logger.info(\"Processing Membership Data\")\n",
        "    process_membership(session, client_data, birth_window_start, birth_window_mid, birth_window_end, client_data)\n",
        "\n",
        "    logger.info(\"Fetching newborn keys\")\n",
        "    newborn_keys = fetch_newborn_keys(session, client_data, birth_window_start, birth_window_end, runout_end)\n",
        "    logger.info(f\"Found {len(newborn_keys)} unique newborn keys\")\n",
        "\n",
        "    logger.info(\"Loading newborn claims\")\n",
        "    claims_df = load_newborn_claims(session, client_data, newborn_keys, birth_window_start, birth_window_end, runout_end)\n",
        "\n",
        "    logger.info(\"Creating the temporary Elig table\")\n",
        "    elig_df = create_fa_elig(session, client_data)\n",
        "\n",
        "    logger.info(\"Merging eligibility data\")\n",
        "    claims_df = merge_eligibility(session, client_data, newborn_keys, claims_df, elig_df).cache_result()\n",
        "\n",
        "    logger.info(\"Assigning Claim Types\")\n",
        "    claims_df = assign_claim_type(claims_df).cache_result()\n",
        "\n",
        "    logger.info(\"Flagging newborn and NICU enrichments\")\n",
        "    claims_df = tag_all_reference_flags(session, claims_df)\n",
        "    # DEBUG: Cache claims after tagging for inspection\n",
        "    if DEBUG_MODE:\n",
        "        claims_df_tagged = claims_df.cache_result()\n",
        "        logger.info(f\"[DEBUG] Cached claims_df_tagged ({claims_df_tagged.count():,} rows)\")\n",
        "    else:\n",
        "        claims_df_tagged = None\n",
        "    logger.info(\"Selecting final claim columns and materializing results...\")\n",
        "    claims_df = claims_df.select(\n",
        "        \"INDV_ID\",\"CLM_AUD_NBR\",\"SRVC_FROM_DT\",\"SRVC_THRU_DT\",\"PROCESS_DT\",\"ADMIT_DT\",\"DISCH_DT\",\n",
        "        \"DIAG_1_CD\",\"DIAG_2_CD\",\"DIAG_3_CD\",\"DIAG_4_CD\",\"DIAG_5_CD\",\"PROC_1_CD\",\"PROC_2_CD\",\"PROC_3_CD\",\"PROC_CD\",\n",
        "        \"DSCHRG_STS\",\"BILLED\",\"DRG\",\"NET_PD_AMT\",\"PL_OF_SRVC_CD\",\"RVNU_CD\",\n",
        "        \"PROV_TIN\",\"PROV_FULL_NM\",\"PROV_STATE\",\"PROV_TYP_CD\",\n",
        "        \"GENDER\",\"BTH_DT\",\"BUS_LINE_CD\",\"PRDCT_CD\",\"STATE\",\n",
        "        \"NEWBORN_ICD\",\"NEWBORN_REV\",\"SINGLE\",\"TWIN\",\"MULTIPLE\",\"NICU_REV\",\"NICU_MSDRG\",\"NICU_APRDRG\",\n",
        "        \"CLAIM_TYPE\"\n",
        "    ).cache_result()\n",
        "    \n",
        "    logger.info(\"Applying newborn rollup logic\")\n",
        "    newborns_df, claims_df = newborn_rollup(session, client_data, claims_df)\n",
        "    \n",
        "    # DEBUG: Cache newborn claims for inspection\n",
        "    if DEBUG_MODE:\n",
        "        newborn_claims = claims_df.cache_result()\n",
        "        logger.info(f\"[DEBUG] Cached newborn_claims ({newborn_claims.count():,} rows)\")\n",
        "    else:\n",
        "        newborn_claims = None\n",
        "    logger.info(\"Rolling up hospital stays\")\n",
        "    hosp_rollup_df = build_hosp_rollup(claims_df, runout_end)\n",
        "    \n",
        "    logger.info(\"Building NICU artifact tables\")\n",
        "    ids = build_newborn_and_nicu_ids(\n",
        "        claims_df,\n",
        "        hosp_rollup_df,\n",
        "        birth_window_start.date(), \n",
        "        birth_window_mid.date(),\n",
        "        init_hosp_threshold_days=INIT_HOSP_THRESHOLD_DAYS,\n",
        "        readmit_threshold_days=READMIT_THRESHOLD_DAYS\n",
        "    )\n",
        "    \n",
        "    newborn_hosp_clms   = ids[\"newborn_hosp_clms\"]\n",
        "    newborn_ident_df    = ids[\"newborn_ident_df\"]\n",
        "    nicu_ident          = ids[\"nicu_ident\"]\n",
        "    nicu_claims_df      = ids[\"nicu_claims_df\"]\n",
        "    nicu_dischg_provider= ids[\"nicu_dischg_provider\"]\n",
        "    rev_out             = ids[\"rev_out\"]\n",
        "    drg_out             = ids[\"drg_out\"]\n",
        "    # Debug retention - cache intermediate dataframes when DEBUG_MODE is enabled\n",
        "    if DEBUG_MODE:\n",
        "        logger.info(\"[DEBUG] Caching intermediate dataframes for inspection...\")\n",
        "        newborn_ident_df = newborn_ident_df.cache_result()\n",
        "        nicu_ident = nicu_ident.cache_result()\n",
        "        logger.info(f\"[DEBUG] Cached newborn_ident_df ({newborn_ident_df.count():,} rows)\")\n",
        "        logger.info(f\"[DEBUG] Cached nicu_ident ({nicu_ident.count():,} rows)\")\n",
        "    logger.info(\"Building NICU rollup\")\n",
        "    nicu_rollup = build_nicu_rollup(\n",
        "        session,\n",
        "        nicu_ident,\n",
        "        nicu_claims_df,\n",
        "        hosp_rollup_df,\n",
        "        rev_out,\n",
        "        drg_out,\n",
        "        nicu_dischg_provider\n",
        "    )\n",
        "    \n",
        "    logger.info(\"Merging Newborns and NICU tables\")\n",
        "    newborns_df = prepare_final_export(newborn_ident_df, nicu_rollup)\n",
        "    \n",
        "    export_to_snowflake(newborns_df, f\"CSZNB_PRD_PS_PFA_DB.BASE.PS_NEWBORNS_{client_data}{TABLE_SUFFIX}\")\n",
        "    # Return debug dataframes when DEBUG_MODE is enabled\n",
        "    if DEBUG_MODE:\n",
        "        return {\n",
        "            # Priority 1: Critical debugging variables\n",
        "            'newborn_ident_df': newborn_ident_df,      # Final newborn identities\n",
        "            'nicu_ident': nicu_ident,                  # NICU subset\n",
        "            'newborns_df': newborns_df,                # Output table\n",
        "            'nicu_rollup': nicu_rollup,                # NICU aggregations\n",
        "            \n",
        "            # Priority 1: Critical intermediate dataframes\n",
        "            'claims_df_tagged': claims_df_tagged,      # Claims after flag tagging\n",
        "            'hosp_rollup_df': hosp_rollup_df,          # Hospital episodes (KEY!)\n",
        "            'newborn_claims': newborn_claims,          # Claims after newborn rollup\n",
        "            \n",
        "            # Priority 2: Detailed analysis variables\n",
        "            'newborn_hosp_clms': newborn_hosp_clms,    # Claims bounded to episodes\n",
        "            'nicu_claims_df': nicu_claims_df,          # NICU claims detail\n",
        "            'nicu_dischg_provider': nicu_dischg_provider,  # Discharge providers\n",
        "            'rev_out': rev_out,                        # Revenue code analysis\n",
        "            'drg_out': drg_out                         # DRG analysis\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute Pipeline\n",
        "\n",
        "Run the main pipeline with the configured parameters above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the pipeline with configuration from the first cell\n",
        "if __name__ == \"__main__\":\n",
        "    result = main(auto_window=AUTO_WINDOW)\n",
        "    \n",
        "    # Extract debug dataframes if DEBUG_MODE was enabled\n",
        "    if DEBUG_MODE and result is not None:\n",
        "        # Priority 1: Core outputs\n",
        "        newborn_ident_df = result['newborn_ident_df']\n",
        "        nicu_ident = result['nicu_ident']\n",
        "        newborns_df = result['newborns_df']\n",
        "        nicu_rollup = result['nicu_rollup']\n",
        "        \n",
        "        # Priority 1: Critical intermediate dataframes\n",
        "        claims_df_tagged = result['claims_df_tagged']\n",
        "        hosp_rollup_df = result['hosp_rollup_df']\n",
        "        newborn_claims = result['newborn_claims']\n",
        "        \n",
        "        # Priority 2: Detailed analysis\n",
        "        newborn_hosp_clms = result['newborn_hosp_clms']\n",
        "        nicu_claims_df = result['nicu_claims_df']\n",
        "        nicu_dischg_provider = result['nicu_dischg_provider']\n",
        "        rev_out = result['rev_out']\n",
        "        drg_out = result['drg_out']\n",
        "        \n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"  DEBUG MODE: All intermediate dataframes available for inspection\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(\"\\nPRIORITY 1 - Critical Debugging:\")\n",
        "        print(\"  \u2022 claims_df_tagged      : Claims after all reference flags tagged\")\n",
        "        print(\"  \u2022 hosp_rollup_df        : Hospital episodes (CHECK IF EMPTY!)\")\n",
        "        print(\"  \u2022 newborn_claims        : Claims after newborn rollup\")\n",
        "        print(\"  \u2022 newborn_ident_df      : Final newborn identities\")\n",
        "        print(\"  \u2022 nicu_ident            : NICU subset\")\n",
        "        \n",
        "        print(\"\\nPRIORITY 2 - Detailed Analysis:\")\n",
        "        print(\"  \u2022 newborn_hosp_clms     : Claims bounded to hospital episodes\")\n",
        "        print(\"  \u2022 nicu_claims_df        : NICU claims detail\")\n",
        "        print(\"  \u2022 nicu_dischg_provider  : Discharge provider analysis\")\n",
        "        print(\"  \u2022 rev_out               : Revenue code aggregations\")\n",
        "        print(\"  \u2022 drg_out               : DRG aggregations\")\n",
        "        \n",
        "        print(\"\\nOUTPUTS:\")\n",
        "        print(\"  \u2022 newborns_df           : Final newborns output table\")\n",
        "        print(\"  \u2022 nicu_rollup           : NICU rollup table\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DIAGNOSTIC WORKFLOW:\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"# 1. Check claim type distribution\")\n",
        "        print(\"   claims_df_tagged.group_by('CLAIM_TYPE').count().show()\")\n",
        "        print()\n",
        "        print(\"# 2. Check if hosp_rollup_df is empty (likely culprit!)\")\n",
        "        print(\"   print(f'Hospital rollups: {hosp_rollup_df.count():,}')\")\n",
        "        print()\n",
        "        print(\"# 3. If empty, check IP classification\")\n",
        "        print(\"   claims_df_tagged.filter(col('CLAIM_TYPE') == 'IP').count()\")\n",
        "        print()\n",
        "        print(\"# 4. Check NICU revenue codes specifically\")\n",
        "        print(\"   claims_df_tagged.filter(col('REV_CD').between('0170', '0179')).\\\\\")\n",
        "        print(\"       select('REV_CD', 'CLAIM_TYPE').show()\")\n",
        "        print()\n",
        "        print(\"# 5. Export to pandas for detailed inspection\")\n",
        "        print(\"   hosp_rollup_df.limit(100).to_pandas()\")\n",
        "        print(\"=\"*80 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Results Summary\n",
        "\n",
        "Display key metrics and statistics from the pipeline execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display pipeline execution summary\n",
        "# Note: Run this cell after the main pipeline completes\n",
        "\n",
        "try:\n",
        "    # Check if pipeline variables exist\n",
        "    if 'newborn_ident_df' in locals() and 'nicu_ident' in locals():\n",
        "        total_newborns = newborn_ident_df.count()\n",
        "        total_nicu = nicu_ident.count()\n",
        "        nicu_rate = (total_nicu / total_newborns * 100) if total_newborns > 0 else 0\n",
        "        \n",
        "        # Get study year breakdown\n",
        "        study_yr_counts = newborn_ident_df.group_by(\"STUDY_YR\").count().collect()\n",
        "        prev_count = next((row['COUNT'] for row in study_yr_counts if row['STUDY_YR'] == 'Previous'), 0)\n",
        "        curr_count = next((row['COUNT'] for row in study_yr_counts if row['STUDY_YR'] == 'Current'), 0)\n",
        "        \n",
        "        # Calculate costs if available\n",
        "        try:\n",
        "            total_cost_data = nicu_ident.select(ssum(\"TOTAL_NICU_COST\").alias(\"TOTAL\")).collect()[0]\n",
        "            total_nicu_cost = total_cost_data['TOTAL'] if total_cost_data['TOTAL'] else 0\n",
        "            avg_nicu_cost = total_nicu_cost / total_nicu if total_nicu > 0 else 0\n",
        "        except:\n",
        "            total_nicu_cost = None\n",
        "            avg_nicu_cost = None        \n",
        "        # Calculate average LOS if available\n",
        "        try:\n",
        "            from snowflake.snowpark.functions import sum as ssum, count\n",
        "            avg_los_data = nicu_ident.select(ssum(\"LOS\").alias(\"TOTAL_LOS\"), count(\"*\").alias(\"COUNT\")).collect()[0]\n",
        "            total_los = avg_los_data['TOTAL_LOS'] if avg_los_data['TOTAL_LOS'] else 0\n",
        "            avg_los = total_los / avg_los_data['COUNT'] if avg_los_data['COUNT'] > 0 else 0\n",
        "        except:\n",
        "            avg_los = None\n",
        "\n",
        "        \n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"  PIPELINE EXECUTION SUMMARY\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"\\nConfiguration:\")\n",
        "        print(f\"  Client:              {CLIENT_DATA}\")\n",
        "        print(f\"  Database:            {DATABASE}\")\n",
        "        print(f\"  Table Suffix:        {TABLE_SUFFIX}\")\n",
        "        print(f\"  Dry-Run Mode:        {DRY_RUN}\")\n",
        "        \n",
        "        print(f\"\\nDate Windows:\")\n",
        "        if 'birth_window_start' in locals():\n",
        "            print(f\"  Birth Window:        {birth_window_start.date()} to {birth_window_end.date()}\")\n",
        "            print(f\"  Period Split:        {birth_window_mid.date()}\")\n",
        "            print(f\"  Runout End:          {runout_end.date()}\")\n",
        "        \n",
        "        print(f\"\\nNewborn Statistics:\")\n",
        "        print(f\"  Total Newborns:      {total_newborns:,}\")\n",
        "        print(f\"    - Previous Period: {prev_count:,}\")\n",
        "        print(f\"    - Current Period:  {curr_count:,}\")\n",
        "        \n",
        "        print(f\"\\nNICU Statistics:\")\n",
        "        print(f\"  NICU Cases:          {total_nicu:,}\")\n",
        "        print(f\"  NICU Rate:           {nicu_rate:.1f}%\")\n",
        "        \n",
        "        if avg_los is not None:\n",
        "            print(f\"  Average LOS:         {avg_los:.1f} days\")\n",
        "        \n",
        "        if total_nicu_cost is not None:\n",
        "            print(f\"  Total NICU Cost:     ${total_nicu_cost:,.0f}\")\n",
        "            print(f\"  Average Cost/Case:   ${avg_nicu_cost:,.0f}\")\n",
        "        \n",
        "        print(f\"\\nOutput Tables:\")\n",
        "        print(f\"  Membership:          {get_table_name('ps_membership', CLIENT_DATA)}\")\n",
        "        print(f\"  Newborns:            {get_table_name('ps_newborns', CLIENT_DATA)}\")\n",
        "        \n",
        "        print(f\"\\n{'='*70}\\n\")\n",
        "        \n",
        "    else:\n",
        "        print(\"\\n\u26a0 Pipeline has not been executed yet. Run the execution cell first.\\n\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\n\u26a0 Error generating summary: {e}\")\n",
        "    print(\"This cell should be run after the main pipeline execution.\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}